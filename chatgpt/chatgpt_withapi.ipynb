{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa3ee9-62ba-4849-9f83-8584139e295f",
   "metadata": {},
   "source": [
    "## ChatGPT\n",
    "\n",
    "This is just some messing around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6baf77f-b887-437d-b0c6-20cde719d906",
   "metadata": {},
   "source": [
    "Docs:\n",
    "\n",
    "* how to upload images: https://platform.openai.com/docs/guides/vision\n",
    "* types of models: https://stackoverflow.com/questions/75774873/openai-api-error-this-is-a-chat-model-and-not-supported-in-the-v1-completions\n",
    "* token limits: https://platform.openai.com/settings/organization/limits\n",
    "* models: https://platform.openai.com/docs/models/model-endpoint-compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f25dda74-0b62-4a27-9566-aaaa27727c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "017cce17-f4e8-4df6-a3b5-2edef3714601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir_api = '/Users/jnaiman/Dropbox/Paper_JCDL2025/chatgpt_api/' # where to store API results\n",
    "\n",
    "dir_api = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/' #store API results for example-hists\n",
    "\n",
    "key_file = '/Users/jnaiman/.openai/key.txt'\n",
    "\n",
    "jsons_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/' # directory where jsons created with figure are stored\n",
    "imgs_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/imgs/' # where images are stored\n",
    "\n",
    "# for saving temp images for reading in\n",
    "tmp_dir = '/Users/jnaiman/Downloads/tmp/'\n",
    "\n",
    "img_format = 'jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2cf577c-4a80-4fbf-b4a0-8a0a61d16b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from sys import path\n",
    "path.append('../')\n",
    "from utils.llm_utils import parse_qa, load_image, get_img_json_pair, parse_for_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86d2d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_chatgpt(question_list, client, image_path, encoded_image,\n",
    "                    model =\"gpt-4o-mini\", \n",
    "                    tmp_dir = '/Users/jnaiman/Downloads/tmp/',\n",
    "                    test_run = True, fac=1.0, img_format='png',\n",
    "                    verbose=True):\n",
    "    # models as of ~May 2024\n",
    "    #model=\"gpt-4\",\n",
    "    #model=\"gpt-4o\",\n",
    "    #model =\"gpt-4o-mini\",\n",
    "    #model =\"gpt-3.5-turbo\",\n",
    "    #model=\"gpt-3.5-turbo-instruct\",\n",
    "\n",
    "    iFac = 1.0 # just in case we want to progressively make the image smaller\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            # current question format is: ['persona', 'context','question', 'format'] (see readme in example_hists)\n",
    "            question = question_list['context'] + \" \" + question_list['question'] + \" \" + question_list['format']\n",
    "            # lowercase the first word, just in case\n",
    "            question = question.lstrip() # no whitespace\n",
    "            question = question[0].lower() + question[1:]\n",
    "            if verbose: print('   on question:',question)\n",
    "            # Prepare the API request\n",
    "            prompt = f\"I am going to show you an image. Here is the image: [Image: {encoded_image}]. Now, {question}\"\n",
    "            prompt_save = f\"I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, {question}\"\n",
    "            \n",
    "            if not test_run:\n",
    "                # Send the request to the GPT-4o API\n",
    "                response = client.chat.completions.create(\n",
    "                    model = model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": question_list['persona']},\n",
    "                        {\"role\":\"user\", \"content\": [\n",
    "                            {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                            },\n",
    "                            {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                #\"url\": f\"data:image/jpeg;base64,{encoded_image}\" # PNG encoding??? does thsi need to change??\n",
    "                                \"url\": f\"data:image/{img_format};base64,{encoded_image}\" \n",
    "                            }\n",
    "                            }\n",
    "                        ]\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "                success = True\n",
    "            else:\n",
    "                success = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            new_fac = fac/iFac\n",
    "            print('new fac = ', new_fac)\n",
    "            encoded_image = load_image(image_path,fac=new_fac, tmp_dir=tmp_dir)\n",
    "            iFac += 1\n",
    "    \n",
    "    if not test_run:\n",
    "        # Get the response from the API\n",
    "        answer = response.choices[0].message.content\n",
    "        question_list['raw answer'] = answer\n",
    "        # format answer\n",
    "        answer_format = answer.replace(\"```json\\n\",'').replace(\"\\n```\",'')\n",
    "        try:\n",
    "            question_list['Response'] = json.loads(answer_format)\n",
    "        except:\n",
    "            question_list['Response'] = answer_format\n",
    "            question_list['Error'] = 'JSON formatting'\n",
    "        question_list['Response String'] = answer_format\n",
    "        success = True\n",
    "    else:\n",
    "        question_list['Response'] = 'TEST RUN'\n",
    "        question_list['Response String'] = 'TEST RUN'\n",
    "\n",
    "    return question_list, prompt_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6eb280d-d109-4a03-8a76-ea47d5f8960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "with open(key_file,'r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=api_key.strip(),  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8957d21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_3_trial9.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_5_trial3.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_2_trial0.json']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_to_parse = glob(jsons_dir + '/*.json')\n",
    "jsons_to_parse[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 4\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/nclust_3_trial9.pickle\n",
      "on 1 of 4\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/nclust_5_trial3.pickle\n",
      "on 2 of 4\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/nclust_2_trial0.pickle\n",
      "on 3 of 4\n",
      "   on question: how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "   on question: what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "   on question: what are the median data values in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median\" value should be a float, calculated from the data values used to create the plot.\n",
      "   on question: what are the minimum data values in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum\" value should be a float, calculated from the data values used to create the plot.\n",
      "   on question: how many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "Q: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "ChatGPT A: {'nbars': 50}\n",
      "Real A:    50\n",
      "\n",
      "Q: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "ChatGPT A: {'maximum x': '1.0'}\n",
      "Real A:    0.9937474970967795\n",
      "\n",
      "Q: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the minimum data values in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum\" value should be a float, calculated from the data values used to create the plot.\n",
      "ChatGPT A: {'minimum x': 0.8}\n",
      "Real A:    0.7019343870423396\n",
      "\n",
      "Q: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "ChatGPT A: {'ngaussians': 3}\n",
      "Real A:    3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iMax = 4\n",
    "verbose = False\n",
    "test_run = False # run w/o actually pinging openai\n",
    "restart = False\n",
    "model =\"gpt-4o-mini\"\n",
    "\n",
    "fac = 0.5\n",
    "for ijson,json_path in enumerate(jsons_to_parse):\n",
    "    if ijson >= iMax:\n",
    "        continue\n",
    "\n",
    "    print('on', ijson, 'of', iMax)\n",
    "\n",
    "    # get image and base json\n",
    "    img_path = imgs_dir + json_path.split('/')[-1].removesuffix('.json') + '.' + img_format\n",
    "    encoded_image, img_format_media, base_json, err = get_img_json_pair(img_path, json_path, dir_api, \n",
    "                                                      fac=fac, restart=restart,\n",
    "                                                      tmp_dir=tmp_dir)\n",
    "\n",
    "    if err:\n",
    "        continue\n",
    "\n",
    "\n",
    "    ###### create QA ########\n",
    "    qa = []\n",
    "    \n",
    "    for k,v in base_json['VQA']['Level 1']['Figure-level questions'].items():\n",
    "        out = {'Q':v['Q'], 'A':v['A'], 'Level':'Level 1', 'type':'Figure-level questions', 'Response':\"\"}\n",
    "        qa.append(out)\n",
    "    \n",
    "    # what kinds?\n",
    "    types = ['(words + list)', '(words)']\n",
    "    \n",
    "    # get uniques\n",
    "    level_parse = 'Level 1'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 2'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 3'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "\n",
    "    responses = []\n",
    "    for question_list in qa:\n",
    "        response, prompt = send_to_chatgpt(question_list, client, img_path, encoded_image,\n",
    "                    model = model, img_format = img_format_media,\n",
    "                    test_run = test_run)\n",
    "        responses.append(response)\n",
    "        question_list['prompt'] = prompt\n",
    "\n",
    "    # parse for errors\n",
    "    qa = parse_for_errors(qa)\n",
    "\n",
    "    # dump to file\n",
    "    if not test_run:\n",
    "        with open(dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle', 'wb') as ff:\n",
    "            pickle.dump([qa, model], ff)\n",
    "        print(\"just saved:\", dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n",
    "    else:\n",
    "        print('Would store at:', dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042a456-e8cf-484f-958c-75cb9b0f9606",
   "metadata": {},
   "source": [
    "## Look at data\n",
    "\n",
    "Check out one, if you wanna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6974b8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/nclust_5_trial3.pickle',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/nclust_3_trial5.pickle',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/nclust_3_trial9.pickle',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/nclust_2_trial0.pickle']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickles = glob(dir_api + '*.pickle')\n",
    "pickles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "636df058",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifile = 1\n",
    "with open(pickles[ifile], 'rb') as f:\n",
    "    qa_in = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11948f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/nclust_3_trial5.pickle\n",
      "*********\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "   Real A: 50\n",
      "ChatGPT A: {'nbars': 50}\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "   Real A: 0.9937474970967795\n",
      "ChatGPT A: {'maximum x': '1.0'}\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "   Real A: 0.8280702357864604\n",
      "ChatGPT A: I'm unable to directly analyze or compute values from images. To find the mean data values for the figure panel you've provided, you'll need to look at the histogram and calculate the mean based on the data it represents.\n",
      "\n",
      "If you have access to the data or can transcribe the values from the histogram, I can help guide you on how to calculate the mean or format it as JSON. Would you like help with that?\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the median data values in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median\" value should be a float, calculated from the data values used to create the plot.\n",
      "   Real A: 0.7942881461671237\n",
      "ChatGPT A: I'm unable to extract or calculate data values from the image of the plot. If you have numerical data or specific values to analyze, please provide that information, and I'd be happy to assist!\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the minimum data values in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum\" value should be a float, calculated from the data values used to create the plot.\n",
      "   Real A: 0.7019343870423396\n",
      "ChatGPT A: {'minimum x': 0.8}\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "   Real A: 3\n",
      "ChatGPT A: {'ngaussians': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pickles[ifile])\n",
    "print('*********')\n",
    "for qa_pairs in qa_in:\n",
    "    print('Prompt:', qa_pairs['prompt'])\n",
    "    print('   Real A:', qa_pairs['A'])\n",
    "    print('ChatGPT A:', qa_pairs['Response'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d309dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JCDL2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
