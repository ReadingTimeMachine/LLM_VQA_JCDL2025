{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa3ee9-62ba-4849-9f83-8584139e295f",
   "metadata": {},
   "source": [
    "## ChatGPT with Few Shot\n",
    "\n",
    "Include some examples for ChatGPT of histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6baf77f-b887-437d-b0c6-20cde719d906",
   "metadata": {},
   "source": [
    "Docs:\n",
    "\n",
    "* how to upload images: https://platform.openai.com/docs/guides/vision\n",
    "* types of models: https://stackoverflow.com/questions/75774873/openai-api-error-this-is-a-chat-model-and-not-supported-in-the-v1-completions\n",
    "* token limits: https://platform.openai.com/settings/organization/limits\n",
    "* models: https://platform.openai.com/docs/models/model-endpoint-compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f25dda74-0b62-4a27-9566-aaaa27727c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017cce17-f4e8-4df6-a3b5-2edef3714601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir_api = '/Users/jnaiman/Dropbox/Paper_JCDL2025/chatgpt_api/' # where to store API results\n",
    "\n",
    "dir_api = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api_fewshot/' #store API results for example-hists\n",
    "\n",
    "key_file = '/Users/jnaiman/.openai/key.txt'\n",
    "\n",
    "# for fewshot\n",
    "fewshot_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/fewshot/' # assume images in \"imgs\", jsons in \"jsons\"\n",
    "\n",
    "# for testing images\n",
    "jsons_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/' # directory where jsons created with figure are stored\n",
    "imgs_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/imgs/' # where images are stored\n",
    "\n",
    "# for saving temp images for reading in\n",
    "tmp_dir = '/Users/jnaiman/Downloads/tmp/'\n",
    "\n",
    "img_format = 'jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2cf577c-4a80-4fbf-b4a0-8a0a61d16b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "\n",
    "# debug\n",
    "from importlib import reload\n",
    "\n",
    "from sys import path\n",
    "path.append('../')\n",
    "import utils.llm_utils\n",
    "reload(utils.llm_utils)\n",
    "from utils.llm_utils import parse_qa, load_image, get_img_json_pair, parse_for_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cddbfe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_question_and_prompt(question_list, encoded_image, verbose = True):\n",
    "    # current question format is: ['persona', 'context','question', 'format'] (see readme in example_hists)\n",
    "    question = question_list['context'] + \" \" + question_list['question'] + \" \" + question_list['format']\n",
    "    # lowercase the first word, just in case\n",
    "    question = question.lstrip() # no whitespace\n",
    "    question = question[0].lower() + question[1:]\n",
    "    if verbose: print('   on question:',question)\n",
    "    # Prepare the API request\n",
    "    prompt = f\"I am going to show you an image. Here is the image: [Image: {encoded_image}]. Now, {question}\"\n",
    "    prompt_save = f\"I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, {question}\"\n",
    "    return prompt, prompt_save, question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855459bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fewshot(fewshot_dir, question_list, \n",
    "                   tmp_dir = '/Users/jnaiman/Downloads/tmp/',\n",
    "                   img_dir = 'imgs', json_dir = 'jsons',\n",
    "                   fac = 1.0, restart=False, verbose=False, \n",
    "                    types = ['(words + list)', '(words)']\n",
    "):\n",
    "    # get question\n",
    "    #question = \n",
    "    prompt = 'Here are some example questions with figures and their respective answers. Reference examples delimited with “”\"\\n'\n",
    "    prompt += '\"\"\"\\n'\n",
    "    prompt_dummy = deepcopy(prompt)\n",
    "    json_files = glob(fewshot_dir + '/' + json_dir + '/*')\n",
    "    # print(fewshot_dir + '/' + json_dir + '/*')\n",
    "    # print(json_files)\n",
    "    if verbose:\n",
    "        print('MAIN QUESTION:', question_list['Q'])\n",
    "    for json_path in json_files:\n",
    "        if verbose: \n",
    "            print('-------- JSON: ' + json_path, '-----------------')\n",
    "        img_path = imgs_dir + json_path.split('/')[-1].removesuffix('.json') + '.' + img_format\n",
    "        encoded_image, img_format_media, base_json, err = get_img_json_pair(img_path, json_path, None, \n",
    "                                                            fac=fac, restart=restart,\n",
    "                                                            tmp_dir=tmp_dir)\n",
    "        \n",
    "        if err:\n",
    "            print('[ERROR]: error in create_fewshot')\n",
    "            print('json_path:', json_path)\n",
    "            print('dir_api:', dir_api)\n",
    "            continue\n",
    "        # response, prompt_dummy_full = send_to_chatgpt(question_list, client, img_path, encoded_image,\n",
    "        #             model = model, img_format = img_format_media,\n",
    "        #             test_run = True, subset_questions_by_keys=subset_questions_by_keys)\n",
    "        _, prompt_dummy_full, _ =  make_question_and_prompt(question_list, encoded_image, verbose = verbose)\n",
    "\n",
    "        #**HERE** response['a'] needs to be from each image loaded here's json!\n",
    "        # level_parse = 'Level 3'\n",
    "        # plot_level = 'Plot-level questions'\n",
    "        # qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "        qa = []\n",
    "        level_parse = question_list['Level']\n",
    "        plot_level = question_list['type']\n",
    "        try:\n",
    "            qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "        except Exception as e:\n",
    "            print('[ERROR]:', str(e))\n",
    "            print('base json is:', base_json)\n",
    "        # pick the right question to get the right answer\n",
    "        answer = None\n",
    "        for qa_pair in qa:\n",
    "            if qa_pair['Q'] == question_list['Q']:\n",
    "                answer = qa_pair['A']\n",
    "        if answer is None:\n",
    "            print(\"[ERROR]: question not found\")\n",
    "            print('qa:')\n",
    "            print(qa)\n",
    "            print('----------')\n",
    "            print('question list:', question_list)\n",
    "            print('****************')\n",
    "            import sys; sys.exit()\n",
    "        elif verbose:\n",
    "            print('Answer:', answer)\n",
    "\n",
    "        prompt_dummy += 'QUESTION: ' + prompt_dummy_full + '\\n'\n",
    "        prompt_dummy += 'ANSWER: ' + str(answer) + '\\n'\n",
    "        prompt_dummy += '\"\"\"\\n'\n",
    "        # replace text\n",
    "        replace_text = f\"{encoded_image}\"\n",
    "        prompt += 'QUESTION: ' + prompt_dummy_full.replace('[Image: <ENCODED IMAGE>]', replace_text) + '\\n'\n",
    "        prompt += 'ANSWER: ' + str(answer) + '\\n'\n",
    "        prompt += '\"\"\"\\n'\n",
    "\n",
    "    # stuff\n",
    "    #prompt += '\"\"\"'\n",
    "    return prompt, prompt_dummy #, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834a47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907cc1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN QUESTION: You are a helpful assistant that can analyze images.  How many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "-------- JSON: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/fewshot//jsons/id_0000.json -----------------\n",
      "   on question: how many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5. Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "Answer: 2\n",
      "-------- JSON: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/fewshot//jsons/id_0001.json -----------------\n",
      "   on question: how many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5. Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "Answer: 5\n",
      "-------- JSON: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/fewshot//jsons/id_0004.json -----------------\n",
      "   on question: how many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5. Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "Answer: 1\n"
     ]
    }
   ],
   "source": [
    "# test one\n",
    "fac = 1.0\n",
    "question_list_test = {'Q': 'You are a helpful assistant that can analyze images.  How many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.',\n",
    " 'A': 1,\n",
    " 'Level': 'Level 3',\n",
    " 'type': 'Plot-level questions',\n",
    " 'Response': 'TEST RUN',\n",
    " 'persona': 'You are a helpful assistant that can analyze images.',\n",
    " 'context': '',\n",
    " 'question': 'How many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5.',\n",
    " 'format': 'Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.',\n",
    " 'plot number': 'plot0',\n",
    " 'Response String': 'TEST RUN',\n",
    " 'prompt': 'I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5. Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.',\n",
    " 'extra sys prompt': ''\n",
    " }\n",
    "prompt_sys, prompt_dummy_sys = create_fewshot(fewshot_dir, \n",
    "                                                question_list_test, \n",
    "                                                tmp_dir = tmp_dir,\n",
    "                                                fac = fac, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a759a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some example questions with figures and their respective answers. Reference examples delimited with “”\"\n",
      "\"\"\"\n",
      "QUESTION: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5. Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "ANSWER: 2\n",
      "\"\"\"\n",
      "QUESTION: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5. Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "ANSWER: 5\n",
      "\"\"\"\n",
      "QUESTION: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5. Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "ANSWER: 1\n",
      "\"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_dummy_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f84324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d2d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_chatgpt(question_list, client, image_path, encoded_image,\n",
    "                    model =\"gpt-4o-mini\", \n",
    "                    tmp_dir = '/Users/jnaiman/Downloads/tmp/',\n",
    "                    test_run = True, fac=1.0, img_format='png',\n",
    "                    verbose=True, \n",
    "                    subset_questions_by_keys = None,\n",
    "                    use_fewshot = False,\n",
    "                    types = ['(words + list)', '(words)']\n",
    "                        ):\n",
    "    # models as of ~May 2024\n",
    "    #model=\"gpt-4\",\n",
    "    #model=\"gpt-4o\",\n",
    "    #model =\"gpt-4o-mini\",\n",
    "    #model =\"gpt-3.5-turbo\",\n",
    "    #model=\"gpt-3.5-turbo-instruct\",\n",
    "    \"\"\"\n",
    "    subset_questions_by_keys : only use a subset of questions to ping to model, e.g. ['median', 'how many gaussians']\n",
    "    use_fewshot : if True will use some examples from the fewshot directory\n",
    "    \"\"\"\n",
    "\n",
    "    iFac = 1.0 # just in case we want to progressively make the image smaller\n",
    "    success = False\n",
    "    is_subset = False\n",
    "    prompt_dummy_sys = ''\n",
    "    while not success:\n",
    "        try:\n",
    "            # # current question format is: ['persona', 'context','question', 'format'] (see readme in example_hists)\n",
    "            # question = question_list['context'] + \" \" + question_list['question'] + \" \" + question_list['format']\n",
    "            # # lowercase the first word, just in case\n",
    "            # question = question.lstrip() # no whitespace\n",
    "            # question = question[0].lower() + question[1:]\n",
    "            # if verbose: print('   on question:',question)\n",
    "            # # Prepare the API request\n",
    "            # prompt = f\"I am going to show you an image. Here is the image: [Image: {encoded_image}]. Now, {question}\"\n",
    "            # prompt_save = f\"I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, {question}\"\n",
    "            prompt, prompt_save, question =  make_question_and_prompt(question_list, encoded_image, verbose = verbose)\n",
    "\n",
    "            if subset_questions_by_keys is not None and type(subset_questions_by_keys) == type([]): # make sure list\n",
    "                for s in subset_questions_by_keys:\n",
    "                    if s in question:\n",
    "                        is_subset = True\n",
    "            else:\n",
    "                is_subset = True\n",
    "            \n",
    "            if not test_run and is_subset:\n",
    "                if use_fewshot:\n",
    "                    #print(\"HI THERE\")\n",
    "                    prompt_sys, prompt_dummy_sys = create_fewshot(fewshot_dir, \n",
    "                                                                 question_list, \n",
    "                                                                 tmp_dir = tmp_dir,\n",
    "                                                                 fac = fac, types=types)\n",
    "                else:\n",
    "                    prompt_sys = ''; prompt_dummy_sys = ''\n",
    "                # Send the request to the GPT-4o API\n",
    "                response = client.chat.completions.create(\n",
    "                    model = model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": question_list['persona'] + ' ' + prompt_sys},\n",
    "                        {\"role\":\"user\", \"content\": [\n",
    "                            {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                            },\n",
    "                            {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                #\"url\": f\"data:image/jpeg;base64,{encoded_image}\" # PNG encoding??? does thsi need to change??\n",
    "                                \"url\": f\"data:image/{img_format};base64,{encoded_image}\" \n",
    "                            }\n",
    "                            }\n",
    "                        ]\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "                success = True\n",
    "            elif not is_subset:\n",
    "                response = 'Not asked'\n",
    "                success = True\n",
    "            elif use_fewshot:\n",
    "                prompt_sys, prompt_dummy_sys = create_fewshot(fewshot_dir, \n",
    "                                                                question_list, \n",
    "                                                                tmp_dir = tmp_dir,\n",
    "                                                                fac = fac, types=types)\n",
    "                success = True\n",
    "            else:\n",
    "                success = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            new_fac = fac/iFac\n",
    "            print('new fac = ', new_fac)\n",
    "            encoded_image = load_image(image_path,fac=new_fac, tmp_dir=tmp_dir)\n",
    "            iFac += 1\n",
    "            #import sys; sys.exit()\n",
    "            #success = True\n",
    "            # break\n",
    "            klaksljf\n",
    "    \n",
    "    if not test_run and is_subset:\n",
    "        # Get the response from the API\n",
    "        answer = response.choices[0].message.content\n",
    "        question_list['raw answer'] = answer\n",
    "        # format answer\n",
    "        answer_format = answer.replace(\"```json\\n\",'').replace(\"\\n```\",'')\n",
    "        try:\n",
    "            question_list['Response'] = json.loads(answer_format)\n",
    "        except:\n",
    "            question_list['Response'] = answer_format\n",
    "            question_list['Error'] = 'JSON formatting'\n",
    "        question_list['Response String'] = answer_format\n",
    "        success = True\n",
    "    elif not is_subset:\n",
    "        answer = response\n",
    "        question_list['raw answer'] = answer\n",
    "        question_list['Response'] = answer\n",
    "        question_list['Response String'] = answer\n",
    "        success = True\n",
    "    else:\n",
    "        question_list['Response'] = 'TEST RUN'\n",
    "        question_list['Response String'] = 'TEST RUN'\n",
    "\n",
    "    return question_list, prompt_save, prompt_dummy_sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04dab3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_qa(pickle_file, qa_in, subset_questions_by_keys=None, showNotAsked=False):\n",
    "    if subset_questions_by_keys is not None:\n",
    "        print('---------- ASKED ----------')\n",
    "    print(pickle_file)\n",
    "    print('*********')\n",
    "    for qa_pairs in qa_in:\n",
    "        hasSub = False\n",
    "        if subset_questions_by_keys is not None and type(subset_questions_by_keys) == type([]):\n",
    "            for s in subset_questions_by_keys:\n",
    "                if s in qa_pairs['prompt']:\n",
    "                    hasSub = True\n",
    "        else:\n",
    "            hasSub = True\n",
    "\n",
    "        if hasSub:\n",
    "            print('Prompt:', qa_pairs['prompt'])\n",
    "            print('   Real A:', qa_pairs['A'])\n",
    "            print('ChatGPT A:', qa_pairs['Response'])\n",
    "            print('')\n",
    "\n",
    "    if subset_questions_by_keys is not None and showNotAsked:\n",
    "        print('')\n",
    "        print('')\n",
    "        print('------------ NOT ASKED -----------')\n",
    "        for qa_pairs in qa_in:\n",
    "            hasSub = False\n",
    "            if subset_questions_by_keys is not None and type(subset_questions_by_keys) == type([]):\n",
    "                for s in subset_questions_by_keys:\n",
    "                    if s in qa_pairs['prompt']:\n",
    "                        hasSub = True\n",
    "\n",
    "            if not hasSub:\n",
    "                print('Prompt:', qa_pairs['prompt'])\n",
    "                print('   Real A:', qa_pairs['A'])\n",
    "                print('ChatGPT A:', qa_pairs['Response'])\n",
    "                print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6eb280d-d109-4a03-8a76-ea47d5f8960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "with open(key_file,'r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=api_key.strip(),  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8957d21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0077.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0020.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0036.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_to_parse = glob(jsons_dir + '/*.json')\n",
    "jsons_to_parse[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8382b9",
   "metadata": {},
   "source": [
    "Look at a possible questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e019153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Level 1': {'Figure-level questions': {},\n",
       "  'Plot-level questions': {'nbars': {'plot0': {'Q': 'You are a helpful assistant that can analyze images.  How many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.',\n",
       "     'A': {'nbars': 20},\n",
       "     'persona': 'You are a helpful assistant that can analyze images.',\n",
       "     'context': '',\n",
       "     'question': 'How many bars are there in the specified figure panel?',\n",
       "     'format': 'Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.'}}}},\n",
       " 'Level 2': {'Plot-level questions': {'minimum': {'plot0': {'Q': 'You are a helpful assistant that can analyze images.  What are the minimum data values  in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "     'A': {'minimum': {'minimum x': -0.9039030182959754}},\n",
       "     'persona': 'You are a helpful assistant that can analyze images.',\n",
       "     'context': '',\n",
       "     'question': 'What are the minimum data values  in this figure panel? ',\n",
       "     'format': 'Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum x\" value should be a float, calculated from the data values used to create the plot.'}},\n",
       "   'maximum': {'plot0': {'Q': 'You are a helpful assistant that can analyze images.  What are the maximum data values  in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "     'A': {'maximum': {'maximum x': -0.1500760324875851}},\n",
       "     'persona': 'You are a helpful assistant that can analyze images.',\n",
       "     'context': '',\n",
       "     'question': 'What are the maximum data values  in this figure panel? ',\n",
       "     'format': 'Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum x\" value should be a float, calculated from the data values used to create the plot.'}},\n",
       "   'median': {'plot0': {'Q': 'You are a helpful assistant that can analyze images.  What are the median data values  in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "     'A': {'median': {'median x': -0.4723913577551772}},\n",
       "     'persona': 'You are a helpful assistant that can analyze images.',\n",
       "     'context': '',\n",
       "     'question': 'What are the median data values  in this figure panel? ',\n",
       "     'format': 'Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a float, calculated from the data values used to create the plot.'}},\n",
       "   'mean': {'plot0': {'Q': 'You are a helpful assistant that can analyze images.  What are the mean data values  in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "     'A': {'mean': {'mean x': -0.49127551258688784}},\n",
       "     'persona': 'You are a helpful assistant that can analyze images.',\n",
       "     'context': '',\n",
       "     'question': 'What are the mean data values  in this figure panel? ',\n",
       "     'format': 'Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean x\" value should be a float, calculated from the data values used to create the plot.'}}}},\n",
       " 'Level 3': {'Plot-level questions': {'ngaussians': {'plot0': {'Q': 'You are a helpful assistant that can analyze images.  How many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.',\n",
       "     'A': {'ngaussians': 2},\n",
       "     'persona': 'You are a helpful assistant that can analyze images.',\n",
       "     'context': '',\n",
       "     'question': 'How many gaussians were used to generate the data for the plot in the figure panel?',\n",
       "     'format': 'Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.'}},\n",
       "   'ngaussians, integer': {'plot0': {'Q': 'You are a helpful assistant that can analyze images.  How many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.',\n",
       "     'A': {'ngaussians': 2},\n",
       "     'persona': 'You are a helpful assistant that can analyze images.',\n",
       "     'context': '',\n",
       "     'question': 'How many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5.',\n",
       "     'format': 'Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.'}}}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_path = jsons_to_parse[0]\n",
    "verbose = False\n",
    "restart = False\n",
    "\n",
    "fac = 0.5\n",
    "\n",
    "img_path = imgs_dir + json_path.split('/')[-1].removesuffix('.json') + '.' + img_format\n",
    "encoded_image, img_format_media, base_json, err = get_img_json_pair(img_path, json_path, None, \n",
    "                                                    fac=fac, restart=restart,\n",
    "                                                    tmp_dir=tmp_dir)\n",
    "\n",
    "base_json['VQA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60b9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0bc7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = \"gpt-5-nano-2025-08-07\"\n",
    "#subset_questions_by_keys = ['median', 'ngaussians'] # set to None to do all questions\n",
    "\n",
    "#p, pf, response = create_fewshot(fewshot_dir, dir_api, question_list, model, subset_questions_by_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a03fccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b02ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62da723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 1 of 80 : id_0077.json\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api_fewshot/id_0077.pickle\n",
      "on 2 of 80 : id_0020.json\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api_fewshot/id_0020.pickle\n",
      "on 3 of 80 : id_0036.json\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api_fewshot/id_0036.pickle\n",
      "on 4 of 80 : id_0061.json\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api_fewshot/id_0061.pickle\n",
      "on 5 of 80 : id_0016.json\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api_fewshot/id_0016.pickle\n",
      "on 6 of 80 : id_0041.json\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api_fewshot/id_0041.pickle\n",
      "on 7 of 80 : id_0057.json\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api_fewshot/id_0057.pickle\n",
      "on 8 of 80 : id_0000.json\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api_fewshot/id_0000.pickle\n",
      "on 9 of 80 : id_0001.json\n",
      "   on question: how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "   on question: what are the maximum data values  in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum x\" value should be a float, calculated from the data values used to create the plot.\n",
      "   on question: what are the mean data values  in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean x\" value should be a float, calculated from the data values used to create the plot.\n",
      "   on question: what are the median data values  in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a float, calculated from the data values used to create the plot.\n"
     ]
    }
   ],
   "source": [
    "iMax = 150 # should be 80\n",
    "verbose = False\n",
    "test_run = False # run w/o actually pinging openai\n",
    "restart = False\n",
    "print_sysprompt = False\n",
    "use_fewshot = True\n",
    "#model =\"gpt-4o-mini\"\n",
    "model = \"gpt-5-nano-2025-08-07\"\n",
    "\n",
    "subset_questions_by_keys = ['median', 'ngaussians'] # set to None to do all questions\n",
    "\n",
    "fac = 0.5\n",
    "for ijson,json_path in enumerate(jsons_to_parse):\n",
    "    if ijson >= iMax:\n",
    "        continue\n",
    "\n",
    "    print('on', ijson+1, 'of', min(iMax,len(jsons_to_parse)), ':', json_path.split('/')[-1])\n",
    "\n",
    "    # get image and base json\n",
    "    img_path = imgs_dir + json_path.split('/')[-1].removesuffix('.json') + '.' + img_format\n",
    "    encoded_image, img_format_media, base_json, err = get_img_json_pair(img_path, json_path, dir_api, \n",
    "                                                      fac=fac, restart=restart,\n",
    "                                                      tmp_dir=tmp_dir)\n",
    "\n",
    "    if err:\n",
    "        continue\n",
    "\n",
    "\n",
    "    ###### create QA ########\n",
    "    qa = []\n",
    "    \n",
    "    for k,v in base_json['VQA']['Level 1']['Figure-level questions'].items():\n",
    "        out = {'Q':v['Q'], 'A':v['A'], 'Level':'Level 1', 'type':'Figure-level questions', 'Response':\"\"}\n",
    "        qa.append(out)\n",
    "    \n",
    "    # what kinds?\n",
    "    types = ['(words + list)', '(words)']\n",
    "    \n",
    "    # get uniques\n",
    "    level_parse = 'Level 1'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 2'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 3'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "\n",
    "    responses = []\n",
    "    for question_list in qa:\n",
    "        response, prompt, prompt_sys = send_to_chatgpt(question_list, client, img_path, encoded_image,\n",
    "                    model = model, img_format = img_format_media,\n",
    "                    test_run = test_run, subset_questions_by_keys=subset_questions_by_keys, \n",
    "                    types=types, use_fewshot=use_fewshot)\n",
    "        responses.append(response)\n",
    "        question_list['prompt'] = prompt\n",
    "        question_list['extra sys prompt'] = prompt_sys\n",
    "        if print_sysprompt:\n",
    "            print('       System prompt:', prompt_sys)\n",
    "\n",
    "    # parse for errors\n",
    "    qa = parse_for_errors(qa)\n",
    "\n",
    "    # dump to file\n",
    "    if not test_run:\n",
    "        with open(dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle', 'wb') as ff:\n",
    "            pickle.dump([qa, model], ff)\n",
    "        print(\"just saved:\", dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n",
    "    else:\n",
    "        print('Would store at:', dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "55263b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0077.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0020.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0036.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0061.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0016.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0041.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0057.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0000.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0001.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0056.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0040.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0017.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0060.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0037.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0021.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0076.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0010.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0047.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0051.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0006.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0071.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0026.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0030.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0067.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0066.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0031.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0027.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0070.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0007.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0050.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0046.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0011.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0004.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0053.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0045.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0012.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0069.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0028.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0008.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0049.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0065.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0032.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0024.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0073.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0072.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0025.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0033.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0064.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0048.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0009.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0029.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0068.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0013.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0044.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0052.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0005.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0059.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0018.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0063.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0034.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0022.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0075.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0002.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0055.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0043.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0014.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0038.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0079.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0078.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0039.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0015.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0042.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0054.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0003.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0074.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0023.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0035.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0062.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0019.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/id_0058.json']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_to_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e83c4b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Q': 'You are a helpful assistant that can analyze images.  How many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.',\n",
       "  'A': 60,\n",
       "  'Level': 'Level 1',\n",
       "  'type': 'Plot-level questions',\n",
       "  'Response': 'Not asked',\n",
       "  'persona': 'You are a helpful assistant that can analyze images.',\n",
       "  'context': '',\n",
       "  'question': 'How many bars are there in the specified figure panel?',\n",
       "  'format': 'Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.',\n",
       "  'plot number': 'plot0',\n",
       "  'raw answer': 'Not asked',\n",
       "  'Response String': 'Not asked',\n",
       "  'prompt': 'I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.'},\n",
       " {'Q': 'You are a helpful assistant that can analyze images.  What are the maximum data values  in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "  'A': 0.65014878688299,\n",
       "  'Level': 'Level 2',\n",
       "  'type': 'Plot-level questions',\n",
       "  'Response': 'Not asked',\n",
       "  'persona': 'You are a helpful assistant that can analyze images.',\n",
       "  'context': '',\n",
       "  'question': 'What are the maximum data values  in this figure panel? ',\n",
       "  'format': 'Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "  'plot number': 'plot0',\n",
       "  'raw answer': 'Not asked',\n",
       "  'Response String': 'Not asked',\n",
       "  'prompt': 'I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the maximum data values  in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum x\" value should be a float, calculated from the data values used to create the plot.'},\n",
       " {'Q': 'You are a helpful assistant that can analyze images.  What are the mean data values  in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "  'A': 0.1515462148624535,\n",
       "  'Level': 'Level 2',\n",
       "  'type': 'Plot-level questions',\n",
       "  'Response': 'Not asked',\n",
       "  'persona': 'You are a helpful assistant that can analyze images.',\n",
       "  'context': '',\n",
       "  'question': 'What are the mean data values  in this figure panel? ',\n",
       "  'format': 'Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "  'plot number': 'plot0',\n",
       "  'raw answer': 'Not asked',\n",
       "  'Response String': 'Not asked',\n",
       "  'prompt': 'I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the mean data values  in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean x\" value should be a float, calculated from the data values used to create the plot.'},\n",
       " {'Q': 'You are a helpful assistant that can analyze images.  What are the median data values  in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "  'A': 0.09764789273740451,\n",
       "  'Level': 'Level 2',\n",
       "  'type': 'Plot-level questions',\n",
       "  'Response': 'TEST RUN',\n",
       "  'persona': 'You are a helpful assistant that can analyze images.',\n",
       "  'context': '',\n",
       "  'question': 'What are the median data values  in this figure panel? ',\n",
       "  'format': 'Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "  'plot number': 'plot0',\n",
       "  'Response String': 'TEST RUN',\n",
       "  'prompt': 'I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the median data values  in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a float, calculated from the data values used to create the plot.'},\n",
       " {'Q': 'You are a helpful assistant that can analyze images.  What are the minimum data values  in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "  'A': -0.17866418690838107,\n",
       "  'Level': 'Level 2',\n",
       "  'type': 'Plot-level questions',\n",
       "  'Response': 'Not asked',\n",
       "  'persona': 'You are a helpful assistant that can analyze images.',\n",
       "  'context': '',\n",
       "  'question': 'What are the minimum data values  in this figure panel? ',\n",
       "  'format': 'Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum x\" value should be a float, calculated from the data values used to create the plot.',\n",
       "  'plot number': 'plot0',\n",
       "  'raw answer': 'Not asked',\n",
       "  'Response String': 'Not asked',\n",
       "  'prompt': 'I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the minimum data values  in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum x\" value should be a float, calculated from the data values used to create the plot.'},\n",
       " {'Q': 'You are a helpful assistant that can analyze images.  How many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.',\n",
       "  'A': 2,\n",
       "  'Level': 'Level 3',\n",
       "  'type': 'Plot-level questions',\n",
       "  'Response': 'TEST RUN',\n",
       "  'persona': 'You are a helpful assistant that can analyze images.',\n",
       "  'context': '',\n",
       "  'question': 'How many gaussians were used to generate the data for the plot in the figure panel?',\n",
       "  'format': 'Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.',\n",
       "  'plot number': 'plot0',\n",
       "  'Response String': 'TEST RUN',\n",
       "  'prompt': 'I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.'},\n",
       " {'Q': 'You are a helpful assistant that can analyze images.  How many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.',\n",
       "  'A': 2,\n",
       "  'Level': 'Level 3',\n",
       "  'type': 'Plot-level questions',\n",
       "  'Response': 'TEST RUN',\n",
       "  'persona': 'You are a helpful assistant that can analyze images.',\n",
       "  'context': '',\n",
       "  'question': 'How many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5.',\n",
       "  'format': 'Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.',\n",
       "  'plot number': 'plot0',\n",
       "  'Response String': 'TEST RUN',\n",
       "  'prompt': 'I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please choose an integer number from 1 to 5. Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042a456-e8cf-484f-958c-75cb9b0f9606",
   "metadata": {},
   "source": [
    "## Look at data\n",
    "\n",
    "Check out one, if you wanna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6974b8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/id_0039.pickle',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/id_0044.pickle',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/id_0027.pickle',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/id_0056.pickle',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/id_0035.pickle']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickles = glob(dir_api + '*.pickle')\n",
    "pickles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636df058",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifile = 0\n",
    "with open(pickles[ifile], 'rb') as f:\n",
    "    qa_in = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11948f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- ASKED ----------\n",
      "/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/chatgpt_api/id_0039.pickle\n",
      "*********\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the median data values  in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a float, calculated from the data values used to create the plot.\n",
      "   Real A: 0.2655385491960254\n",
      "ChatGPT A: {'median x': 0.27}\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "   Real A: 3\n",
      "ChatGPT A: {'ngaussians': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_qa(pickles[ifile], qa_in, subset_questions_by_keys=subset_questions_by_keys, showNotAsked=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d309dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JCDL2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
