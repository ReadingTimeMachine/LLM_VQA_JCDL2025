{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa3ee9-62ba-4849-9f83-8584139e295f",
   "metadata": {},
   "source": [
    "## Claude.ai\n",
    "\n",
    "This is just some messing around with the `example_hists` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6baf77f-b887-437d-b0c6-20cde719d906",
   "metadata": {},
   "source": [
    "### Docs:\n",
    "\n",
    "* in theory, there is documentation here: https://docs.anthropic.com/en/home, \n",
    "* but in reality I just asked \"Hey Claude.  How do I use your API through Python to upload an image and ask you questions about it?\" followed by \"Is there anyway to set the context?  For example, in chatgpt you have the \"\"role\": \"system\", \"content\"\" part of your message where you would say things like \"You are a helpful assistant in charge of automating a process\".  Or does one just incorporate that into the \"question\" part of the inputs?\" and starting building from there\n",
    "\n",
    "#### Key Points (cp-claude)\n",
    "\n",
    "* API Key: Get your API key from the [Anthropic Console](https://console.anthropic.com/) and set it as an environment variable or pass it directly\n",
    "* Supported formats: JPEG, PNG, GIF, and WebP images\n",
    "* Model: Use `claude-sonnet-4-20250514` for Claude Sonnet 4\n",
    "* Size limits: Images should be under 5MB and no larger than 8000x8000 pixels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68139a2",
   "metadata": {},
   "source": [
    "First, install anthropic api (also, see .yml file for the environment for this project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb6c6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d71599",
   "metadata": {},
   "source": [
    "Where are things stored/going to be stored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acfdd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_api = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/claude_api/' #store API results for example-hists\n",
    "\n",
    "key_file = '/Users/jnaiman/.claudeai/key.txt'\n",
    "\n",
    "jsons_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/' # directory where jsons created with figure are stored\n",
    "imgs_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/imgs/' # where images are stored\n",
    "\n",
    "# for saving temp images for reading in\n",
    "tmp_dir = '/Users/jnaiman/Downloads/tmp/'\n",
    "\n",
    "img_format = 'jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c959f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import base64\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# debug\n",
    "from importlib import reload\n",
    "from anthropic import RateLimitError\n",
    "\n",
    "\n",
    "from sys import path\n",
    "path.append('../')\n",
    "import utils.llm_utils\n",
    "reload(utils.llm_utils)\n",
    "from utils.llm_utils import parse_qa, load_image, get_img_json_pair, parse_for_errors\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c219777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "with open(key_file,'r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "  api_key=api_key.strip(),  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceaea9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_3_trial9.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_5_trial3.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_2_trial0.json']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_to_parse = glob(jsons_dir + '/*.json')\n",
    "jsons_to_parse[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99b23a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_claude(question_list, client, image_path, encoded_image,\n",
    "                    model=\"claude-sonnet-4-20250514\",\n",
    "                    max_tokens=1000, temperature=0.1,\n",
    "                    media_type = 'image/png',\n",
    "                    tmp_dir = '/Users/jnaiman/Downloads/tmp/',\n",
    "                    test_run = True, fac=1.0, \n",
    "                    verbose=True,\n",
    "                    system_prompt = None, \n",
    "                    max_retries = 10, sleep_time=1):\n",
    "    \"\"\"\n",
    "    Sends the question to claude and collects response.clear\n",
    "\n",
    "    system_prompt : if None, then defaults to the overall system prompt generated with the questions.\n",
    "    \"\"\"\n",
    "    if system_prompt is None:\n",
    "        system_prompt = question_list['persona']\n",
    "\n",
    "    print('system prompt:', system_prompt)\n",
    "\n",
    "    iFac = 1.0\n",
    "    success = False\n",
    "    #['persona', 'context','question', 'format']\n",
    "    attempt = 0\n",
    "    while not success and attempt < max_retries:\n",
    "        try:\n",
    "            question = question_list['context'] + \" \" + question_list['question'] + \" \" + question_list['format']\n",
    "            # lowercase the first word, just in case\n",
    "            question = question.lstrip() # no whitespace\n",
    "            question = question[0].lower() + question[1:]\n",
    "            if verbose: print('   on question:',question)\n",
    "            # Prepare the API request\n",
    "            prompt = f\"I am going to show you an image. Here is the image: [Image: {encoded_image}]. Now, {question}\"\n",
    "            prompt_save = f\"I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, {question}\"\n",
    "            ##question_list['prompt'] = prompt\n",
    "            \n",
    "            if not test_run:\n",
    "                # Send the request to the GPT-4o API\n",
    "                response = client.messages.create(\n",
    "                    model = model,\n",
    "                    max_tokens=max_tokens,\n",
    "                    system = system_prompt,\n",
    "                    temperature=temperature,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"type\": \"image\",\n",
    "                                    \"source\": {\n",
    "                                        \"type\": \"base64\",\n",
    "                                        \"media_type\": media_type,\n",
    "                                        \"data\": encoded_image,\n",
    "                                    },\n",
    "                                },\n",
    "                                {\n",
    "                                    \"type\": \"text\",\n",
    "                                    \"text\": prompt\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "                        # {\"role\": \"system\", \"content\": question_list['persona']},\n",
    "                        # {\"role\":\"user\", \"content\": [\n",
    "                        #     {\n",
    "                        #     \"type\": \"text\",\n",
    "                        #     \"text\": prompt\n",
    "                        #     },\n",
    "                        #     {\n",
    "                        #     \"type\": \"image_url\",\n",
    "                        #     \"image_url\": {\n",
    "                        #         \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                        #     }\n",
    "                        #     }\n",
    "                        # ]\n",
    "                        # }\n",
    "                    ]\n",
    "                )\n",
    "                success = True\n",
    "            else:\n",
    "                success = True\n",
    "        except RateLimitError as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                # Exponential backoff with jitter\n",
    "                wait_time = sleep_time*(2 ** (attempt)) + np.random.uniform(0, 1)\n",
    "                print(f\"Rate limit hit. Waiting {wait_time:.2f} seconds before retry {attempt + 1}\")\n",
    "                time.sleep(wait_time)\n",
    "                attempt += 1\n",
    "            else:\n",
    "                print(f\"Max retries exceeded. Error: {e}\")\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            new_fac = fac/iFac\n",
    "            print('new fac = ', new_fac)\n",
    "            encoded_image = load_image(image_path,fac=new_fac, tmp_dir=tmp_dir)\n",
    "            iFac += 1\n",
    "    \n",
    "    print(response)\n",
    "    if not test_run:\n",
    "        # Get the response from the API\n",
    "        answer = response.content[0].text #response.choices[0].message.content\n",
    "        question_list['raw answer'] = answer\n",
    "        # format answer\n",
    "        answer_format = answer.split('```json\"')[-1].split('\\n')[0].replace('\\n', '')\n",
    "        #answer.replace(\"```json\\n\",'').replace(\"\\n```\",'')\n",
    "        try:\n",
    "            question_list['Response'] = json.loads(answer_format)\n",
    "        except:\n",
    "            question_list['Response'] = answer_format\n",
    "            question_list['Error'] = 'JSON formatting'\n",
    "        question_list['Response String'] = answer_format\n",
    "        success = True\n",
    "    else:\n",
    "        question_list['Response'] = 'TEST RUN'\n",
    "        question_list['Response String'] = 'TEST RUN'\n",
    "\n",
    "    return question_list, prompt_save, system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de214bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 2\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/claude_api/nclust_3_trial9.pickle\n",
      "on 1 of 2\n",
      "system prompt: You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.\n",
      "   on question: how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "Message(id='msg_011KicAmf3xWhdwkm3vWp4x3', content=[TextBlock(citations=None, text='I need to analyze the bar chart in the image to count the number of bars.\\n\\nLooking at the figure, I can see a bar chart with bars of different heights. Let me count each individual bar from left to right:\\n\\n1. First bar (leftmost)\\n2. Second bar\\n3. Third bar\\n4. Fourth bar\\n5. Fifth bar\\n6. Sixth bar\\n7. Seventh bar\\n8. Eighth bar\\n9. Ninth bar\\n10. Tenth bar\\n11. Eleventh bar\\n12. Twelfth bar\\n13. Thirteenth bar\\n14. Fourteenth bar\\n15. Fifteenth bar\\n16. Sixteenth bar\\n17. Seventeenth bar\\n18. Eighteenth bar\\n19. Nineteenth bar\\n20. Twentieth bar (rightmost)\\n\\nI can see there are 20 individual bars in this histogram/bar chart.\\n\\n{\"nbars\":\"20\"}', type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=76946, output_tokens=207, server_tool_use=None, service_tier='standard'))\n"
     ]
    }
   ],
   "source": [
    "iMax = 2\n",
    "verbose = False\n",
    "test_run = False # run w/o actually pinging openai\n",
    "restart = False\n",
    "model =\"claude-sonnet-4-20250514\"\n",
    "max_tokens=500\n",
    "# set system_prompt to None to default to what is in question list\n",
    "system_prompt = \"\"\"You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.\"\"\"\n",
    "#system_prompt = \"\"\"You must respond with only valid JSON. Start your response immediately with { and end with }. Do not write any text before or after the JSON.\"\"\"\n",
    "temperature=0.1\n",
    "fac = 1.0\n",
    "sleep = 60 # seconds\n",
    "\n",
    "\n",
    "for ijson,json_path in enumerate(jsons_to_parse):\n",
    "    if ijson >= iMax:\n",
    "        continue\n",
    "\n",
    "    print('on', ijson, 'of', iMax)\n",
    "\n",
    "    # get image and base json\n",
    "    img_path = imgs_dir + json_path.split('/')[-1].removesuffix('.json') + '.' + img_format\n",
    "    encoded_image, img_format_media, base_json, err = get_img_json_pair(img_path, json_path, dir_api, \n",
    "                                                      fac=fac, restart=restart,\n",
    "                                                      tmp_dir=tmp_dir)\n",
    "    if err:\n",
    "        continue\n",
    "\n",
    "    ###### create QA ########\n",
    "    qa = []\n",
    "    \n",
    "    for k,v in base_json['VQA']['Level 1']['Figure-level questions'].items():\n",
    "        out = {'Q':v['Q'], 'A':v['A'], 'Level':'Level 1', 'type':'Figure-level questions', 'Response':\"\"}\n",
    "        qa.append(out)\n",
    "    \n",
    "    # what kinds?\n",
    "    types = ['(words + list)', '(words)']\n",
    "    \n",
    "    # get uniques\n",
    "    level_parse = 'Level 1'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 2'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 3'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "\n",
    "    responses = []\n",
    "    for question_list in qa:\n",
    "        response, prompt, system_prompt_out = send_to_claude(question_list, client, img_path, encoded_image,\n",
    "                    model = model, max_tokens=max_tokens, media_type='image/' + img_format_media,\n",
    "                    test_run = test_run, system_prompt=system_prompt, temperature=temperature, \n",
    "                    sleep_time=sleep)\n",
    "        responses.append(response)\n",
    "        question_list['prompt'] = prompt\n",
    "        question_list['system prompt'] = system_prompt_out\n",
    "        #import sys; sys.exit() # just do one\n",
    "        time.sleep(sleep)\n",
    "    time.sleep(sleep)\n",
    "\n",
    "    # parse for errors\n",
    "    qa = parse_for_errors(qa, llm='claude')\n",
    "\n",
    "    # dump to file\n",
    "    if not test_run:\n",
    "        with open(dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle', 'wb') as ff:\n",
    "            pickle.dump([qa, model], ff)\n",
    "    else:\n",
    "        print('Would store at:', dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n",
    "    #import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b90896",
   "metadata": {},
   "source": [
    "## Look at data\n",
    "\n",
    "Check out one, if you wanna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8540406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/claude_api/nclust_3_trial9.pickle']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickles = glob(dir_api + '*.pickle')\n",
    "#pickles = glob('/Users/jnaiman/Downloads/tmp/JCDL2025/example_hists/claude_api/*pickle')\n",
    "pickles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc36f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifile = 0\n",
    "with open(pickles[ifile], 'rb') as f:\n",
    "    qa_in = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63377f",
   "metadata": {},
   "source": [
    "Claude outputs reasoning, so we have to do a bit of cleaning from the responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e69ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/claude_api/nclust_3_trial9.pickle\n",
      "*********\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "  Real A: 50\n",
      "Claude A: {'nbars': '50'}\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.49755257997301794\n",
      "Claude A: {'maximum x': '0.5'}\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.34264837991488106\n",
      "Claude A: {'mean x': '0.33'}\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the median data values in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.3895267656798662\n",
      "Claude A: {'median x': '0.3'}\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, what are the minimum data values in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.15863689997095148\n",
      "Claude A: {'minimum x': 0.1}\n",
      "\n",
      "Prompt: I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "  Real A: 3\n",
      "Claude A: {'ngaussians': '2'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pickles[ifile])\n",
    "print('*********')\n",
    "for qa_pairs in qa_in:\n",
    "    print('Prompt:', qa_pairs['prompt'])\n",
    "    print('  Real A:', qa_pairs['A'])\n",
    "    #response = qa_pairs['Response'].split('```json')\n",
    "    response_claude = qa_pairs['raw answer']\n",
    "    if '```json' in response_claude: # ideal\n",
    "        response_claude = response_claude.split('```json')[-1].split('```')[0].replace('\\n','')\n",
    "        response_claude = json.loads(response_claude)\n",
    "    elif '{\"' in response_claude: # less ideal\n",
    "        response_claude = '{\"' + response_claude.split('{\"')[-1].replace('\\n','')\n",
    "        response_claude = json.loads(response_claude)\n",
    "    print('Claude A:', response_claude)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57affca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JCDL2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
