{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa3ee9-62ba-4849-9f83-8584139e295f",
   "metadata": {},
   "source": [
    "## Claude.ai\n",
    "\n",
    "This is just some messing around with the `example_hists` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6baf77f-b887-437d-b0c6-20cde719d906",
   "metadata": {},
   "source": [
    "### Docs:\n",
    "\n",
    "* in theory, there is documentation here: https://docs.anthropic.com/en/home, \n",
    "* but in reality I just asked \"Hey Claude.  How do I use your API through Python to upload an image and ask you questions about it?\" followed by \"Is there anyway to set the context?  For example, in chatgpt you have the \"\"role\": \"system\", \"content\"\" part of your message where you would say things like \"You are a helpful assistant in charge of automating a process\".  Or does one just incorporate that into the \"question\" part of the inputs?\" and starting building from there\n",
    "\n",
    "#### Key Points (cp-claude)\n",
    "\n",
    "* API Key: Get your API key from the [Anthropic Console](https://console.anthropic.com/) and set it as an environment variable or pass it directly\n",
    "* Supported formats: JPEG, PNG, GIF, and WebP images\n",
    "* Model: Use `claude-sonnet-4-20250514` for Claude Sonnet 4\n",
    "* Size limits: Images should be under 5MB and no larger than 8000x8000 pixels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68139a2",
   "metadata": {},
   "source": [
    "First, install anthropic api (also, see .yml file for the environment for this project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6c6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d71599",
   "metadata": {},
   "source": [
    "Where are things stored/going to be stored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acfdd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_api = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/claude_api/' #store API results for example-hists\n",
    "\n",
    "key_file = '/Users/jnaiman/.claudeai/key.txt'\n",
    "\n",
    "jsons_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/' # directory where jsons created with figure are stored\n",
    "imgs_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/imgs/' # where images are stored\n",
    "\n",
    "# for saving temp images for reading in\n",
    "tmp_dir = '/Users/jnaiman/Downloads/tmp/'\n",
    "\n",
    "img_format = 'jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c959f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import base64\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# debug\n",
    "from importlib import reload\n",
    "from anthropic import RateLimitError\n",
    "\n",
    "\n",
    "from sys import path\n",
    "path.append('../')\n",
    "import utils.llm_utils\n",
    "reload(utils.llm_utils)\n",
    "from utils.llm_utils import parse_qa, load_image, get_img_json_pair, parse_for_errors\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c219777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "with open(key_file,'r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "  api_key=api_key.strip(),  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ceaea9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_3_trial9.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_5_trial3.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_2_trial0.json']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_to_parse = glob(jsons_dir + '/*.json')\n",
    "jsons_to_parse[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b23a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_claude(question_list, client, image_path, encoded_image,\n",
    "                    model=\"claude-sonnet-4-20250514\",\n",
    "                    max_tokens=1000, temperature=0.1,\n",
    "                    media_type = 'image/png',\n",
    "                    tmp_dir = '/Users/jnaiman/Downloads/tmp/',\n",
    "                    test_run = True, fac=1.0, \n",
    "                    verbose=True,\n",
    "                    system_prompt = None, \n",
    "                    max_retries = 10, sleep_time=1):\n",
    "    \"\"\"\n",
    "    Sends the question to claude and collects response.clear\n",
    "\n",
    "    system_prompt : if None, then defaults to the overall system prompt generated with the questions.\n",
    "    \"\"\"\n",
    "    if system_prompt is None:\n",
    "        system_prompt = question_list['persona']\n",
    "\n",
    "    print('system prompt:', system_prompt)\n",
    "\n",
    "    iFac = 1.0\n",
    "    success = False\n",
    "    #['persona', 'context','question', 'format']\n",
    "    attempt = 0\n",
    "    while not success and attempt < max_retries:\n",
    "        try:\n",
    "            question = question_list['context'] + \" \" + question_list['question'] + \" \" + question_list['format']\n",
    "            # lowercase the first word, just in case\n",
    "            question = question.lstrip() # no whitespace\n",
    "            question = question[0].lower() + question[1:]\n",
    "            if verbose: print('   on question:',question)\n",
    "            # Prepare the API request\n",
    "            prompt = f\"I am going to show you an image. Here is the image: [Image: {encoded_image}]. Now, {question}\"\n",
    "            prompt_save = f\"I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, {question}\"\n",
    "            ##question_list['prompt'] = prompt\n",
    "            \n",
    "            if not test_run:\n",
    "                # Send the request to the GPT-4o API\n",
    "                response = client.messages.create(\n",
    "                    model = model,\n",
    "                    max_tokens=max_tokens,\n",
    "                    system = system_prompt,\n",
    "                    temperature=temperature,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"type\": \"image\",\n",
    "                                    \"source\": {\n",
    "                                        \"type\": \"base64\",\n",
    "                                        \"media_type\": media_type,\n",
    "                                        \"data\": encoded_image,\n",
    "                                    },\n",
    "                                },\n",
    "                                {\n",
    "                                    \"type\": \"text\",\n",
    "                                    \"text\": prompt\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "                        # {\"role\": \"system\", \"content\": question_list['persona']},\n",
    "                        # {\"role\":\"user\", \"content\": [\n",
    "                        #     {\n",
    "                        #     \"type\": \"text\",\n",
    "                        #     \"text\": prompt\n",
    "                        #     },\n",
    "                        #     {\n",
    "                        #     \"type\": \"image_url\",\n",
    "                        #     \"image_url\": {\n",
    "                        #         \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                        #     }\n",
    "                        #     }\n",
    "                        # ]\n",
    "                        # }\n",
    "                    ]\n",
    "                )\n",
    "                success = True\n",
    "            else:\n",
    "                success = True\n",
    "        except RateLimitError as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                # Exponential backoff with jitter\n",
    "                wait_time = (2 ** (attempt*sleep_time)) + np.random.uniform(0, 1)\n",
    "                print(f\"Rate limit hit. Waiting {wait_time:.2f} seconds before retry {attempt + 1}\")\n",
    "                time.sleep(wait_time)\n",
    "                attempt += 1\n",
    "            else:\n",
    "                print(f\"Max retries exceeded. Error: {e}\")\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            new_fac = fac/iFac\n",
    "            print('new fac = ', new_fac)\n",
    "            encoded_image = load_image(image_path,fac=new_fac, tmp_dir=tmp_dir)\n",
    "            iFac += 1\n",
    "    \n",
    "    print(response)\n",
    "    if not test_run:\n",
    "        # Get the response from the API\n",
    "        answer = response.content[0].text #response.choices[0].message.content\n",
    "        # format answer\n",
    "        answer_format = answer.replace(\"```json\\n\",'').replace(\"\\n```\",'')\n",
    "        try:\n",
    "            question_list['Response'] = json.loads(answer_format)\n",
    "        except:\n",
    "            question_list['Response'] = answer_format\n",
    "            question_list['Error'] = 'JSON formatting'\n",
    "        question_list['Response String'] = answer_format\n",
    "        success = True\n",
    "    else:\n",
    "        question_list['Response'] = 'TEST RUN'\n",
    "        question_list['Response String'] = 'TEST RUN'\n",
    "\n",
    "    return question_list, prompt_save, system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de214bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 1\n",
      "system prompt: You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.\n",
      "   on question: how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "Message(id='msg_017DFUUiA2k126ma7tFXaq7q', content=[TextBlock(citations=None, text='I need to analyze the histogram image to count the number of bars.\\n\\nLooking at the histogram, I can see it displays a bimodal distribution with bars spanning across the x-axis from approximately 0.1 to 0.5. The histogram appears to have two main peaks - one around 0.2 and another around 0.4.\\n\\nCounting the individual bars from left to right across the entire histogram, I can see there are numerous vertical bars of varying heights that make up this distribution.\\n\\nAfter carefully examining the histogram and counting each individual bar, I count approximately 50 bars total.\\n\\n{\"nbars\": \"50\"}', type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=73852, output_tokens=139, server_tool_use=None, service_tier='standard'))\n",
      "system prompt: You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 1.07 seconds before retry 1\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 2.82 seconds before retry 2\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 4.86 seconds before retry 3\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 8.22 seconds before retry 4\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 16.08 seconds before retry 5\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 32.98 seconds before retry 6\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 64.18 seconds before retry 7\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 128.27 seconds before retry 8\n",
      "   on question: what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "Message(id='msg_01P3snLULESzz8RoJ6wBbfoE', content=[TextBlock(citations=None, text='Looking at this histogram, I can see it shows a bimodal distribution with two main peaks. The x-axis appears to range from approximately 0.1 to 0.5, with the rightmost data extending to around 0.5.\\n\\nBased on the histogram bins and data distribution shown, the maximum x value appears to be approximately 0.5.\\n\\n```json\\n{\"maximum x\": \"0.5\"}\\n```', type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=73863, output_tokens=95, server_tool_use=None, service_tier='standard'))\n",
      "system prompt: You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.\n",
      "   on question: what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 1.88 seconds before retry 1\n",
      "   on question: what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 2.92 seconds before retry 2\n",
      "   on question: what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 4.34 seconds before retry 3\n",
      "   on question: what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 8.22 seconds before retry 4\n",
      "   on question: what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 16.87 seconds before retry 5\n",
      "   on question: what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 32.62 seconds before retry 6\n",
      "   on question: what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "Rate limit hit. Waiting 64.45 seconds before retry 7\n"
     ]
    }
   ],
   "source": [
    "iMax = 1\n",
    "verbose = False\n",
    "test_run = False # run w/o actually pinging openai\n",
    "restart = False\n",
    "model =\"claude-sonnet-4-20250514\"\n",
    "max_tokens=500\n",
    "# set system_prompt to None to default to what is in question list\n",
    "system_prompt = \"\"\"You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.\"\"\"\n",
    "#system_prompt = \"\"\"You must respond with only valid JSON. Start your response immediately with { and end with }. Do not write any text before or after the JSON.\"\"\"\n",
    "temperature=0.1\n",
    "fac = 1.0\n",
    "sleep = 5 # seconds\n",
    "\n",
    "\n",
    "for ijson,json_path in enumerate(jsons_to_parse):\n",
    "    if ijson >= iMax:\n",
    "        continue\n",
    "\n",
    "    print('on', ijson, 'of', iMax)\n",
    "\n",
    "    # get image and base json\n",
    "    img_path = imgs_dir + json_path.split('/')[-1].removesuffix('.json') + '.' + img_format\n",
    "    encoded_image, img_format_media, base_json, err = get_img_json_pair(img_path, json_path, dir_api, \n",
    "                                                      fac=fac, restart=restart,\n",
    "                                                      tmp_dir=tmp_dir)\n",
    "    if err:\n",
    "        continue\n",
    "\n",
    "    ###### create QA ########\n",
    "    qa = []\n",
    "    \n",
    "    for k,v in base_json['VQA']['Level 1']['Figure-level questions'].items():\n",
    "        out = {'Q':v['Q'], 'A':v['A'], 'Level':'Level 1', 'type':'Figure-level questions', 'Response':\"\"}\n",
    "        qa.append(out)\n",
    "    \n",
    "    # what kinds?\n",
    "    types = ['(words + list)', '(words)']\n",
    "    \n",
    "    # get uniques\n",
    "    level_parse = 'Level 1'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 2'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 3'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "\n",
    "    responses = []\n",
    "    for question_list in qa:\n",
    "        response, prompt, system_prompt_out = send_to_claude(question_list, client, img_path, encoded_image,\n",
    "                    model = model, max_tokens=max_tokens, media_type='image/' + img_format_media,\n",
    "                    test_run = test_run, system_prompt=system_prompt, temperature=temperature, \n",
    "                    sleep_time=sleep)\n",
    "        responses.append(response)\n",
    "        question_list['prompt'] = prompt\n",
    "        question_list['system prompt'] = system_prompt_out\n",
    "        #import sys; sys.exit() # just do one\n",
    "        time.sleep(sleep)\n",
    "    time.sleep(sleep)\n",
    "\n",
    "\n",
    "    # parse for errors\n",
    "    qa = parse_for_errors(qa, llm='claude')\n",
    "\n",
    "    # dump to file\n",
    "    if not test_run:\n",
    "        with open(dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle', 'wb') as ff:\n",
    "            pickle.dump([qa, model], ff)\n",
    "    else:\n",
    "        print('Would store at:', dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n",
    "    import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b90896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/imgs/nclust_3_trial9.png'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8540406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q': 'You are a helpful assistant that can analyze images.  How many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.',\n",
       " 'A': 50,\n",
       " 'Level': 'Level 1',\n",
       " 'type': 'Plot-level questions',\n",
       " 'Response': 'Looking at the histogram image, I can see a distribution with multiple bars. The x-axis shows \"x title\" ranging from approximately 0.2 to 0.5, and the y-axis shows \"y axis\" ranging from 0 to 400. The histogram appears to have a bimodal distribution with bars concentrated around two main peaks.\\n\\nCounting the individual bars in the histogram, I can identify approximately 30 distinct bars spanning the range from about 0.2 to 0.5 on the x-axis.\\n\\n{\"nbars\": \"30\"}',\n",
       " 'persona': 'You are a helpful assistant that can analyze images.',\n",
       " 'context': '',\n",
       " 'question': 'How many bars are there in the specified figure panel?',\n",
       " 'format': 'Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.',\n",
       " 'plot number': 'plot0',\n",
       " 'Error': 'JSON formatting',\n",
       " 'Response String': 'Looking at the histogram image, I can see a distribution with multiple bars. The x-axis shows \"x title\" ranging from approximately 0.2 to 0.5, and the y-axis shows \"y axis\" ranging from 0 to 400. The histogram appears to have a bimodal distribution with bars concentrated around two main peaks.\\n\\nCounting the individual bars in the histogram, I can identify approximately 30 distinct bars spanning the range from about 0.2 to 0.5 on the x-axis.\\n\\n{\"nbars\": \"30\"}',\n",
       " 'prompt': 'I am going to show you an image. Here is the image: [Image: <ENCODED IMAGE>]. Now, how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.',\n",
       " 'system prompt': 'You are a helpful assistant that responds only in valid JSON format. \\n    Do not include any explanations, reasoning, or text outside of the JSON response.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc36f1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JCDL2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
