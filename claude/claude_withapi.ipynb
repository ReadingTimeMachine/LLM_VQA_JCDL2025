{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa3ee9-62ba-4849-9f83-8584139e295f",
   "metadata": {},
   "source": [
    "## Claude.ai\n",
    "\n",
    "This is just some messing around with the `example_hists` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6baf77f-b887-437d-b0c6-20cde719d906",
   "metadata": {},
   "source": [
    "### Docs:\n",
    "\n",
    "* in theory, there is documentation here: https://docs.anthropic.com/en/home, \n",
    "* but in reality I just asked \"Hey Claude.  How do I use your API through Python to upload an image and ask you questions about it?\" followed by \"Is there anyway to set the context?  For example, in chatgpt you have the \"\"role\": \"system\", \"content\"\" part of your message where you would say things like \"You are a helpful assistant in charge of automating a process\".  Or does one just incorporate that into the \"question\" part of the inputs?\" and starting building from there\n",
    "\n",
    "#### Key Points (cp-claude)\n",
    "\n",
    "* API Key: Get your API key from the [Anthropic Console](https://console.anthropic.com/) and set it as an environment variable or pass it directly\n",
    "* Supported formats: JPEG, PNG, GIF, and WebP images\n",
    "* Model: Use `claude-sonnet-4-20250514` for Claude Sonnet 4\n",
    "* Size limits: Images should be under 5MB and no larger than 8000x8000 pixels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68139a2",
   "metadata": {},
   "source": [
    "First, install anthropic api (also, see .yml file for the environment for this project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb6c6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d71599",
   "metadata": {},
   "source": [
    "Where are things stored/going to be stored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acfdd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example hists\n",
    "# dir_api = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/claude_api/' #store API results for example-hists\n",
    "# jsons_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/' # directory where jsons created with figure are stored\n",
    "# imgs_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/imgs/' # where images are stored\n",
    "\n",
    "# # example lines\n",
    "# dir_api = '/Users/jnaiman/LLM_VQA_JCDL2025/example_lines/LLM_outputs/claude_api/' #store API results for example-hists\n",
    "# jsons_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_lines/jsons/' # directory where jsons created with figure are stored\n",
    "# imgs_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_lines/imgs/' # where images are stored\n",
    "\n",
    "# example scatters\n",
    "dir_api = '/Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/LLM_outputs/claude_api/' #store API results for example-hists\n",
    "jsons_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/jsons/' # directory where jsons created with figure are stored\n",
    "imgs_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/imgs/' # where images are stored\n",
    "\n",
    "\n",
    "\n",
    "key_file = '/Users/jnaiman/.claudeai/key.txt'\n",
    "# for saving temp images for reading in\n",
    "tmp_dir = '/Users/jnaiman/Downloads/tmp/'\n",
    "\n",
    "img_format = 'jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c959f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import base64\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# debug\n",
    "from importlib import reload\n",
    "from anthropic import RateLimitError\n",
    "\n",
    "\n",
    "from sys import path\n",
    "path.append('../')\n",
    "import utils.llm_utils\n",
    "reload(utils.llm_utils)\n",
    "from utils.llm_utils import parse_qa, load_image, get_img_json_pair, parse_for_errors\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c219777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "with open(key_file,'r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "  api_key=api_key.strip(),  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ceaea9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/jsons/nclust_3_trial9.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/jsons/nclust_5_trial3.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/jsons/nclust_2_trial0.json']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_to_parse = glob(jsons_dir + '/*.json')\n",
    "jsons_to_parse[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99b23a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_claude(question_list, client, image_path, encoded_image,\n",
    "                    model=\"claude-sonnet-4-20250514\",\n",
    "                    max_tokens=1000, temperature=0.1,\n",
    "                    media_type = 'image/png',\n",
    "                    tmp_dir = '/Users/jnaiman/Downloads/tmp/',\n",
    "                    test_run = True, fac=1.0, \n",
    "                    verbose=True,\n",
    "                    system_prompt = None, \n",
    "                    max_retries = 10, sleep_time=1):\n",
    "    \"\"\"\n",
    "    Sends the question to claude and collects response.clear\n",
    "\n",
    "    system_prompt : if None, then defaults to the overall system prompt generated with the questions.\n",
    "    \"\"\"\n",
    "    if system_prompt is None:\n",
    "        system_prompt = question_list['persona']\n",
    "\n",
    "    #print('system prompt:', system_prompt)\n",
    "\n",
    "    iFac = 1.0\n",
    "    success = False\n",
    "    #['persona', 'context','question', 'format']\n",
    "    attempt = 0\n",
    "    while not success and attempt < max_retries:\n",
    "        try:\n",
    "            question = question_list['context'] + \" \" + question_list['question'] + \" \" + question_list['format']\n",
    "            # lowercase the first word, just in case\n",
    "            question = question.lstrip() # no whitespace\n",
    "            question = question[0].lower() + question[1:]\n",
    "            if verbose: print('   on question:',question)\n",
    "            # Prepare the API request\n",
    "            prompt = f\"I am going to show you an image. Now, {question}\"\n",
    "            prompt_save = f\"I am going to show you an image. Now, {question}\"\n",
    "            ##question_list['prompt'] = prompt\n",
    "            \n",
    "            if not test_run:\n",
    "                # Send the request to the Claude api\n",
    "                response = client.messages.create(\n",
    "                    model = model,\n",
    "                    max_tokens=max_tokens,\n",
    "                    system = system_prompt,\n",
    "                    temperature=temperature,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"type\": \"image\",\n",
    "                                    \"source\": {\n",
    "                                        \"type\": \"base64\",\n",
    "                                        \"media_type\": media_type,\n",
    "                                        \"data\": encoded_image,\n",
    "                                    },\n",
    "                                },\n",
    "                                {\n",
    "                                    \"type\": \"text\",\n",
    "                                    \"text\": prompt\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "                success = True\n",
    "            else:\n",
    "                success = True\n",
    "        except RateLimitError as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                # Exponential backoff with jitter\n",
    "                wait_time = sleep_time*(2 ** (attempt)) + np.random.uniform(0, 1)\n",
    "                print(f\"      Rate limit hit. Waiting {wait_time:.2f} seconds before retry {attempt + 1}\")\n",
    "                time.sleep(wait_time)\n",
    "                attempt += 1\n",
    "            else:\n",
    "                print(f\"Max retries exceeded. Error: {e}\")\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            new_fac = fac/iFac\n",
    "            print('      new fac = ', new_fac)\n",
    "            encoded_image = load_image(image_path,fac=new_fac, tmp_dir=tmp_dir)\n",
    "            iFac += 1\n",
    "    \n",
    "    #print(response)\n",
    "    if not test_run:\n",
    "        # Get the response from the API\n",
    "        answer = response.content[0].text #response.choices[0].message.content\n",
    "        question_list['raw answer'] = answer\n",
    "        # also calculate usage\n",
    "        usage = response.usage\n",
    "        question_list['usage'] = usage\n",
    "        if verbose:\n",
    "            print(f\"      - Input tokens: {usage.input_tokens}\")\n",
    "            print(f\"      - Output tokens: {usage.output_tokens}\")\n",
    "            print(f\"      - Total tokens: {usage.input_tokens + usage.output_tokens}\")\n",
    "        # format answer\n",
    "        answer_format = answer.split('```json\"')[-1].split('\\n')[0].replace('\\n', '')\n",
    "        #answer.replace(\"```json\\n\",'').replace(\"\\n```\",'')\n",
    "        try:\n",
    "            question_list['Response'] = json.loads(answer_format)\n",
    "        except:\n",
    "            question_list['Response'] = answer_format\n",
    "            question_list['Error'] = 'JSON formatting'\n",
    "        question_list['Response String'] = answer_format\n",
    "        success = True\n",
    "    else:\n",
    "        question_list['Response'] = 'TEST RUN'\n",
    "        question_list['Response String'] = 'TEST RUN'\n",
    "\n",
    "    return question_list, prompt_save, system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5785e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_for_errors_claude(qa_in, verbose=True):\n",
    "    # there is some \"doubling up\" of strings, so clean up a bit\n",
    "    direct_copy_list = ['Q', 'A', 'Level', 'type', 'persona', \n",
    "                        'context', 'question', 'format', 'plot number', \n",
    "                        'usage', 'prompt', 'system prompt',\n",
    "                        'Response', 'Response String'] # these last 2 will be overwritten\n",
    "    qa_out = []\n",
    "    for qa_pairs in qa_in:\n",
    "        if verbose:\n",
    "            print('Prompt:', qa_pairs['prompt'])\n",
    "            print('  Real A:', qa_pairs['A'])\n",
    "        #response = qa_pairs['Response'].split('```json')\n",
    "        response_claude_raw = qa_pairs['raw answer']\n",
    "        response_claude = ''\n",
    "        try:\n",
    "            if '```json' in response_claude_raw: # ideal\n",
    "                response_claude = response_claude_raw.split('```json')[-1].split('```')[0].replace('\\n','')\n",
    "                response_claude = json.loads(response_claude)\n",
    "            elif '{\"' in response_claude_raw: # less ideal\n",
    "                response_claude = '{\"' + response_claude_raw.split('{\"')[-1].replace('\\n','')\n",
    "                response_claude = json.loads(response_claude)\n",
    "        except json.JSONDecodeError: # last ditch effort\n",
    "            # Extract JSON if there's extra text\n",
    "            json_match = re.search(r'\\{.*\\}', response_claude_raw, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    response_claude = json.loads(json_match.group())\n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "        if verbose:\n",
    "            if response_claude == '':\n",
    "                print(\"ERROR IN CLAUDE PARSE\")\n",
    "            else:\n",
    "                print('Claude A:', response_claude)\n",
    "            print('')\n",
    "        # now clean up\n",
    "        qa_dir = {}\n",
    "        for dc in direct_copy_list:\n",
    "            qa_dir[dc] = qa_pairs[dc]\n",
    "        # overwrite the last two\n",
    "        qa_dir['Response String'] = qa_pairs['raw answer'] # full, un filtered answer\n",
    "        qa_dir['Response'] = response_claude\n",
    "        qa_out.append(qa_dir.copy())\n",
    "    return qa_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de214bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 1\n",
      "/Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/imgs/nclust_3_trial9.jpeg\n",
      "   on question: how many scatter points are there in the specified figure panel? Please format the output as a json as {\"npoints\":\"\"} for this figure panel, where the \"npoints\" value should be an integer.\n",
      "      - Input tokens: 733\n",
      "      - Output tokens: 15\n",
      "      - Total tokens: 748\n",
      "   on question: what are the maximum data values along the color-axis in this figure panel?  Please format the output as a json as {\"maximum color\":\"\"} for this figure panel, where the \"maximum color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 12\n",
      "      - Total tokens: 762\n",
      "   on question: what are the maximum data values along the x-axis in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 12\n",
      "      - Total tokens: 762\n",
      "   on question: what are the maximum data values along the y-axis in this figure panel?  Please format the output as a json as {\"maximum y\":\"\"} for this figure panel, where the \"maximum y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 12\n",
      "      - Total tokens: 762\n",
      "   on question: what are the mean data values along the color-axis in this figure panel?  Please format the output as a json as {\"mean color\":\"\"} for this figure panel, where the \"mean color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 17\n",
      "      - Total tokens: 767\n",
      "   on question: what are the mean data values along the x-axis in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 17\n",
      "      - Total tokens: 767\n",
      "   on question: what are the mean data values along the y-axis in this figure panel?  Please format the output as a json as {\"mean y\":\"\"} for this figure panel, where the \"mean y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 17\n",
      "      - Total tokens: 767\n",
      "   on question: what are the median data values along the color-axis in this figure panel?  Please format the output as a json as {\"median color\":\"\"} for this figure panel, where the \"median color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 17\n",
      "      - Total tokens: 767\n",
      "   on question: what are the median data values along the x-axis in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 17\n",
      "      - Total tokens: 767\n",
      "   on question: what are the median data values along the y-axis in this figure panel?  Please format the output as a json as {\"median y\":\"\"} for this figure panel, where the \"median y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 17\n",
      "      - Total tokens: 767\n",
      "   on question: what are the minimum data values along the color-axis in this figure panel?  Please format the output as a json as {\"minimum color\":\"\"} for this figure panel, where the \"minimum color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 12\n",
      "      - Total tokens: 762\n",
      "   on question: what are the minimum data values along the x-axis in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 12\n",
      "      - Total tokens: 762\n",
      "   on question: what are the minimum data values along the y-axis in this figure panel?  Please format the output as a json as {\"minimum y\":\"\"} for this figure panel, where the \"minimum y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "      - Input tokens: 750\n",
      "      - Output tokens: 12\n",
      "      - Total tokens: 762\n",
      "   on question: what is the underlying distribution used to create the data in this figure panel along the color-axis? Please format the output as a json as {\"distribution color\":\"\"} for this figure panel, where the \"distribution color\" value should be a strings, calculated from the data values used to create the plot. Please choose the distribution from the following list: [random, linear, gaussian mixture model].\n",
      "      - Input tokens: 770\n",
      "      - Output tokens: 15\n",
      "      - Total tokens: 785\n",
      "\n",
      "**** Cleaned QA ****\n",
      "Prompt: I am going to show you an image. Now, how many scatter points are there in the specified figure panel? Please format the output as a json as {\"npoints\":\"\"} for this figure panel, where the \"npoints\" value should be an integer.\n",
      "  Real A: 200\n",
      "Claude A: {'npoints': 150}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the maximum data values along the color-axis in this figure panel?  Please format the output as a json as {\"maximum color\":\"\"} for this figure panel, where the \"maximum color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 1.2824979673586125\n",
      "Claude A: {'maximum color': '1.0'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the maximum data values along the x-axis in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.0344265681406982\n",
      "Claude A: {'maximum x': '0.0'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the maximum data values along the y-axis in this figure panel?  Please format the output as a json as {\"maximum y\":\"\"} for this figure panel, where the \"maximum y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 1.1359932714058731\n",
      "Claude A: {'maximum y': 1.2}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the mean data values along the color-axis in this figure panel?  Please format the output as a json as {\"mean color\":\"\"} for this figure panel, where the \"mean color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.43613062506412775\n",
      "Claude A: {'mean color': '0.5'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the mean data values along the x-axis in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -0.7084337978301525\n",
      "Claude A: {'mean x': -0.75}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the mean data values along the y-axis in this figure panel?  Please format the output as a json as {\"mean y\":\"\"} for this figure panel, where the \"mean y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.2814662085200106\n",
      "Claude A: {'mean y': '0.15'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the median data values along the color-axis in this figure panel?  Please format the output as a json as {\"median color\":\"\"} for this figure panel, where the \"median color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.42059955085304357\n",
      "Claude A: {'median color': '0.5'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the median data values along the x-axis in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -0.7343302298720282\n",
      "Claude A: {'median x': -0.75}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the median data values along the y-axis in this figure panel?  Please format the output as a json as {\"median y\":\"\"} for this figure panel, where the \"median y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.33478565110118286\n",
      "Claude A: {'median y': '0.2'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the minimum data values along the color-axis in this figure panel?  Please format the output as a json as {\"minimum color\":\"\"} for this figure panel, where the \"minimum color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -0.14429022116443055\n",
      "Claude A: {'minimum color': '0.0'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the minimum data values along the x-axis in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -1.1737912687630485\n",
      "Claude A: {'minimum x': -1.2}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the minimum data values along the y-axis in this figure panel?  Please format the output as a json as {\"minimum y\":\"\"} for this figure panel, where the \"minimum y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -0.8625187995746161\n",
      "Claude A: {'minimum y': -0.8}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what is the underlying distribution used to create the data in this figure panel along the color-axis? Please format the output as a json as {\"distribution color\":\"\"} for this figure panel, where the \"distribution color\" value should be a strings, calculated from the data values used to create the plot. Please choose the distribution from the following list: [random, linear, gaussian mixture model].\n",
      "  Real A: gaussian mixture model\n",
      "Claude A: {'distribution color': 'linear'}\n",
      "\n",
      "Just saved: /Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/LLM_outputs/claude_api/nclust_3_trial9.pickle\n"
     ]
    }
   ],
   "source": [
    "iMax = 1\n",
    "verbose = False\n",
    "test_run = False # run w/o actually pinging openai\n",
    "restart = False\n",
    "model =\"claude-sonnet-4-20250514\"\n",
    "max_tokens=500\n",
    "# set system_prompt to None to default to what is in question list\n",
    "system_prompt = \"\"\"You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.\"\"\"\n",
    "#system_prompt = \"\"\"You must respond with only valid JSON. Start your response immediately with { and end with }. Do not write any text before or after the JSON.\"\"\"\n",
    "temperature=0.1\n",
    "fac = 1.0\n",
    "sleep = 5 # seconds\n",
    "use_single_prompt = True # use 1 prompt and 1 image, if False will use multiple at a time\n",
    "\n",
    "import utils.llm_utils\n",
    "reload(utils.llm_utils)\n",
    "from utils.llm_utils import get_img_json_pair\n",
    "\n",
    "for ijson,json_path in enumerate(jsons_to_parse):\n",
    "    if ijson >= iMax:\n",
    "        continue\n",
    "\n",
    "    print('on', ijson, 'of', iMax)\n",
    "\n",
    "    # get image and base json\n",
    "    img_path = imgs_dir + json_path.split('/')[-1].removesuffix('.json') + '.' + img_format\n",
    "    print(img_path)\n",
    "    encoded_image, img_format_media, base_json, err = get_img_json_pair(img_path, json_path, dir_api, \n",
    "                                                      fac=fac, restart=restart,\n",
    "                                                      tmp_dir=tmp_dir)\n",
    "    if err:\n",
    "        continue\n",
    "\n",
    "    ###### create QA ########\n",
    "    qa = []\n",
    "    \n",
    "    for k,v in base_json['VQA']['Level 1']['Figure-level questions'].items():\n",
    "        out = {'Q':v['Q'], 'A':v['A'], 'Level':'Level 1', 'type':'Figure-level questions', 'Response':\"\"}\n",
    "        qa.append(out)\n",
    "    \n",
    "    # what kinds?\n",
    "    types = ['(words + list)', '(words)']\n",
    "    \n",
    "    # get uniques\n",
    "    level_parse = 'Level 1'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 2'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 3'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "\n",
    "    responses = []; prompts = []; system_prompts = []\n",
    "    if use_single_prompt:\n",
    "        for question_list in qa:\n",
    "            response, prompt, system_prompt_out = send_to_claude(question_list, client, img_path, encoded_image,\n",
    "                        model = model, max_tokens=max_tokens, media_type='image/' + img_format_media,\n",
    "                        test_run = test_run, system_prompt=system_prompt, temperature=temperature, \n",
    "                        sleep_time=sleep)\n",
    "            responses.append(response)\n",
    "            question_list['prompt'] = prompt\n",
    "            question_list['system prompt'] = system_prompt_out\n",
    "        #import sys; sys.exit() # just do one\n",
    "        time.sleep(sleep)\n",
    "    time.sleep(sleep)\n",
    "\n",
    "    # parse for errors\n",
    "    #qa = parse_for_errors(qa, llm='claude')\n",
    "    print('')\n",
    "    print('**** Cleaned QA ****')\n",
    "    qa = parse_for_errors_claude(qa)\n",
    "\n",
    "    # dump to file\n",
    "    if not test_run:\n",
    "        with open(dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle', 'wb') as ff:\n",
    "            pickle.dump([qa, model], ff)\n",
    "        print('Just saved:', dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n",
    "    else:\n",
    "        print('Would store at:', dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n",
    "    #import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b90896",
   "metadata": {},
   "source": [
    "## Look at data\n",
    "\n",
    "Check out one, if you wanna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8540406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/LLM_outputs/claude_api/nclust_3_trial9.pickle']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickles = glob(dir_api + '*.pickle')\n",
    "#pickles = glob('/Users/jnaiman/Downloads/tmp/JCDL2025/example_hists/claude_api/*pickle')\n",
    "pickles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc36f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifile = 0\n",
    "with open(pickles[ifile], 'rb') as f:\n",
    "    qa_in = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc0a5ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q': 'You are a helpful assistant that can analyze images.  How many scatter points are there in the specified figure panel? Please format the output as a json as {\"npoints\":\"\"} for this figure panel, where the \"npoints\" value should be an integer.',\n",
       " 'A': 200,\n",
       " 'Level': 'Level 1',\n",
       " 'type': 'Plot-level questions',\n",
       " 'persona': 'You are a helpful assistant that can analyze images.',\n",
       " 'context': '',\n",
       " 'question': 'How many scatter points are there in the specified figure panel?',\n",
       " 'format': 'Please format the output as a json as {\"npoints\":\"\"} for this figure panel, where the \"npoints\" value should be an integer.',\n",
       " 'plot number': 'plot0',\n",
       " 'usage': Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=733, output_tokens=15, server_tool_use=None, service_tier='standard'),\n",
       " 'prompt': 'I am going to show you an image. Now, how many scatter points are there in the specified figure panel? Please format the output as a json as {\"npoints\":\"\"} for this figure panel, where the \"npoints\" value should be an integer.',\n",
       " 'system prompt': 'You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.',\n",
       " 'Response': {'npoints': 150},\n",
       " 'Response String': '```json\\n{\"npoints\": 150}\\n```'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_in[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63377f",
   "metadata": {},
   "source": [
    "Claude outputs reasoning, so we have to do a bit of cleaning from the responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e69ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jnaiman/LLM_VQA_JCDL2025/example_scatters/LLM_outputs/claude_api/nclust_3_trial9.pickle\n",
      "*********\n",
      "Prompt: I am going to show you an image. Now, how many scatter points are there in the specified figure panel? Please format the output as a json as {\"npoints\":\"\"} for this figure panel, where the \"npoints\" value should be an integer.\n",
      "  Real A: 200\n",
      "Claude A: {'npoints': 150}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the maximum data values along the color-axis in this figure panel?  Please format the output as a json as {\"maximum color\":\"\"} for this figure panel, where the \"maximum color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 1.2824979673586125\n",
      "Claude A: {'maximum color': '1.0'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the maximum data values along the x-axis in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.0344265681406982\n",
      "Claude A: {'maximum x': '0.0'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the maximum data values along the y-axis in this figure panel?  Please format the output as a json as {\"maximum y\":\"\"} for this figure panel, where the \"maximum y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 1.1359932714058731\n",
      "Claude A: {'maximum y': 1.2}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the mean data values along the color-axis in this figure panel?  Please format the output as a json as {\"mean color\":\"\"} for this figure panel, where the \"mean color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.43613062506412775\n",
      "Claude A: {'mean color': '0.5'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the mean data values along the x-axis in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -0.7084337978301525\n",
      "Claude A: {'mean x': -0.75}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the mean data values along the y-axis in this figure panel?  Please format the output as a json as {\"mean y\":\"\"} for this figure panel, where the \"mean y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.2814662085200106\n",
      "Claude A: {'mean y': '0.15'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the median data values along the color-axis in this figure panel?  Please format the output as a json as {\"median color\":\"\"} for this figure panel, where the \"median color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.42059955085304357\n",
      "Claude A: {'median color': '0.5'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the median data values along the x-axis in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -0.7343302298720282\n",
      "Claude A: {'median x': -0.75}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the median data values along the y-axis in this figure panel?  Please format the output as a json as {\"median y\":\"\"} for this figure panel, where the \"median y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: 0.33478565110118286\n",
      "Claude A: {'median y': '0.2'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the minimum data values along the color-axis in this figure panel?  Please format the output as a json as {\"minimum color\":\"\"} for this figure panel, where the \"minimum color\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -0.14429022116443055\n",
      "Claude A: {'minimum color': '0.0'}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the minimum data values along the x-axis in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum x\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -1.1737912687630485\n",
      "Claude A: {'minimum x': -1.2}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the minimum data values along the y-axis in this figure panel?  Please format the output as a json as {\"minimum y\":\"\"} for this figure panel, where the \"minimum y\" value should be a floats, calculated from the data values used to create the plot.\n",
      "  Real A: -0.8625187995746161\n",
      "Claude A: {'minimum y': -0.8}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what is the underlying distribution used to create the data in this figure panel along the color-axis? Please format the output as a json as {\"distribution color\":\"\"} for this figure panel, where the \"distribution color\" value should be a strings, calculated from the data values used to create the plot. Please choose the distribution from the following list: [random, linear, gaussian mixture model].\n",
      "  Real A: gaussian mixture model\n",
      "Claude A: {'distribution color': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pickles[ifile])\n",
    "print('*********')\n",
    "for qa_pairs in qa_in:\n",
    "    print('Prompt:', qa_pairs['prompt'])\n",
    "    print('  Real A:', qa_pairs['A'])\n",
    "    print('Claude A:', qa_pairs['Response'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57affca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JCDL2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
