{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa3ee9-62ba-4849-9f83-8584139e295f",
   "metadata": {},
   "source": [
    "## Gemini\n",
    "\n",
    "This is just some messing around with the `example_hists` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6baf77f-b887-437d-b0c6-20cde719d906",
   "metadata": {},
   "source": [
    "### Docs:\n",
    "\n",
    "* in theory, there is documentation here: https://ai.google.dev/gemini-api/docs, \n",
    "* Here though, I just asked claude again :D\n",
    "\n",
    "#### Key Points (cp-claude)\n",
    "\n",
    "* API Key: Get your API key from the [Google Console](https://aistudio.google.com/app/apikey) -- note that you either have to create a new GCP project OR create the API key in an existing project\n",
    "* Then the rest of the steps is similar for Claude/ChatGPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68139a2",
   "metadata": {},
   "source": [
    "First, install anthropic api (also, see .yml file for the environment for this project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6c6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-generativeai pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d71599",
   "metadata": {},
   "source": [
    "Where are things stored/going to be stored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acfdd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_api = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/gemini_api/' #store API results for example-hists\n",
    "\n",
    "key_file = '/Users/jnaiman/.gemini/key.txt'\n",
    "\n",
    "jsons_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/' # directory where jsons created with figure are stored\n",
    "imgs_dir = '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/imgs/' # where images are stored\n",
    "\n",
    "# for saving temp images for reading in\n",
    "tmp_dir = '/Users/jnaiman/Downloads/tmp/'\n",
    "\n",
    "img_format = 'jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c959f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from glob import glob\n",
    "import google.generativeai as genai\n",
    "\n",
    "# debug\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "from sys import path\n",
    "path.append('../')\n",
    "import utils.llm_utils\n",
    "reload(utils.llm_utils)\n",
    "from utils.llm_utils import parse_qa, load_image, get_img_json_pair, parse_for_errors\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c219777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "with open(key_file,'r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "# Configure the API key\n",
    "genai.configure(api_key=api_key.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='gemini-1.5-flash'\n",
    "model_gemini = genai.GenerativeModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceaea9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_3_trial9.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_5_trial3.json',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/jsons/nclust_2_trial0.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons_to_parse = glob(jsons_dir + '/*.json')\n",
    "jsons_to_parse[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "335a9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_gemini(question_list, image_path, model_gemini,\n",
    "                    #tmp_dir = '/Users/jnaiman/Downloads/tmp/',\n",
    "                    test_run = True, \n",
    "                    #fac=1.0, \n",
    "                    verbose=True,\n",
    "                    system_prompt = None,                   \n",
    "                   #model='gemini-1.5-flash',\n",
    "                   large_image= False):\n",
    "    \"\"\"\n",
    "    Sends an image + question to Gemini.  Does something different for large file, but might be bad idea.\n",
    "\n",
    "    system_prompt : set to None to use default from question list\n",
    "    \"\"\"\n",
    "    if system_prompt is None:\n",
    "        system_prompt = question_list['persona']\n",
    "\n",
    "    err = False\n",
    "    #model_gemini = genai.GenerativeModel(model)\n",
    "    #if verbose: print('Model loaded:', model)\n",
    "    prompt_save = ''; prompt = ''; response = ''\n",
    "    if not test_run:\n",
    "        question = question_list['context'] + \" \" + question_list['question'] + \" \" + question_list['format']\n",
    "        # lowercase the first word, just in case\n",
    "        question = question.lstrip() # no whitespace\n",
    "        question = question[0].lower() + question[1:]\n",
    "        if verbose: print('   on question:',question)\n",
    "        # Prepare the API request\n",
    "        prompt = f\"I am going to show you an image. Now, {question}\"\n",
    "        prompt_save = f\"I am going to show you an image. Now, {question}\"\n",
    "        try:\n",
    "        #if True:\n",
    "\n",
    "            # Wait for processing (for video files, you might need to wait longer)\n",
    "            if large_image:\n",
    "                # Upload the file to Gemini\n",
    "                uploaded_file = genai.upload_file(path=image_path)\n",
    "                import time\n",
    "                while uploaded_file.state.name == \"PROCESSING\":\n",
    "                    time.sleep(1)\n",
    "                    uploaded_file = genai.get_file(uploaded_file.name)\n",
    "            else:\n",
    "                uploaded_file = Image.open(image_path)\n",
    "            \n",
    "            # Generate content with the uploaded file\n",
    "            response = model_gemini.generate_content([prompt, uploaded_file])\n",
    "            \n",
    "            if large_image:\n",
    "                # Clean up - delete the uploaded file\n",
    "                genai.delete_file(uploaded_file.name)\n",
    "            \n",
    "            #return response.text\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('[ERROR]:', str(e))\n",
    "            err = True\n",
    "\n",
    "            #return f\"Error: {str(e)}\"\n",
    "        \n",
    "    if not test_run and not err:\n",
    "        # Get the response from the API\n",
    "        answer = response.text \n",
    "        question_list['raw answer'] = answer\n",
    "        # also calculate usage\n",
    "        usage = {\n",
    "            'input_tokens': response.usage_metadata.prompt_token_count,\n",
    "            'output_tokens': response.usage_metadata.candidates_token_count,\n",
    "            'total_tokens': response.usage_metadata.total_token_count,\n",
    "            'cached_content_tokens': getattr(response.usage_metadata, 'cached_content_token_count', 0)\n",
    "            }\n",
    "\n",
    "        question_list['usage'] = usage\n",
    "        if verbose:\n",
    "            print(f\"      - Input tokens: {usage.input_tokens}\")\n",
    "            print(f\"      - Output tokens: {usage.output_tokens}\")\n",
    "            print(f\"      - Total tokens: {usage.input_tokens + usage.output_tokens}\")\n",
    "        # format answer\n",
    "        answer_format = answer.split('```json\"')[-1].split('\\n')[0].replace('\\n', '')\n",
    "        #answer.replace(\"```json\\n\",'').replace(\"\\n```\",'')\n",
    "        try:\n",
    "            question_list['Response'] = json.loads(answer_format)\n",
    "        except:\n",
    "            question_list['Response'] = answer_format\n",
    "            question_list['Error'] = 'JSON formatting'\n",
    "        question_list['Response String'] = answer_format\n",
    "    elif err:\n",
    "        question_list['raw answer'] = 'ERROR'\n",
    "    else:\n",
    "        question_list['Response'] = 'TEST RUN'\n",
    "        question_list['Response String'] = 'TEST RUN'\n",
    "    \n",
    "\n",
    "    return question_list, prompt_save, system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "113ba0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_for_errors_claude(qa_in, verbose=True, llm = 'claude'):\n",
    "    # there is some \"doubling up\" of strings, so clean up a bit\n",
    "    direct_copy_list = ['Q', 'A', 'Level', 'type', 'persona', \n",
    "                        'context', 'question', 'format', 'plot number', \n",
    "                        'usage', 'prompt', 'system prompt',\n",
    "                        'Response', 'Response String'] # these last 2 will be overwritten\n",
    "    qa_out = []\n",
    "    for qa_pairs in qa_in:\n",
    "        if verbose:\n",
    "            print('Prompt:', qa_pairs['prompt'])\n",
    "            print('  Real A:', qa_pairs['A'])\n",
    "        #response = qa_pairs['Response'].split('```json')\n",
    "        response_claude_raw = qa_pairs['raw answer']\n",
    "        response_claude = ''\n",
    "        try:\n",
    "            if '```json' in response_claude_raw: # ideal\n",
    "                response_claude = response_claude_raw.split('```json')[-1].split('```')[0].replace('\\n','')\n",
    "                response_claude = json.loads(response_claude)\n",
    "            elif '{\"' in response_claude_raw: # less ideal\n",
    "                response_claude = '{\"' + response_claude_raw.split('{\"')[-1].replace('\\n','')\n",
    "                response_claude = json.loads(response_claude)\n",
    "        except json.JSONDecodeError: # last ditch effort\n",
    "            # Extract JSON if there's extra text\n",
    "            json_match = re.search(r'\\{.*\\}', response_claude_raw, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    response_claude = json.loads(json_match.group())\n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "        if verbose:\n",
    "            if response_claude == '':\n",
    "                print(\"ERROR IN \"+llm.upper()+\" PARSE\")\n",
    "            else:\n",
    "                print(llm.capitalize() + ' A:', response_claude)\n",
    "            print('')\n",
    "        # now clean up\n",
    "        qa_dir = {}\n",
    "        for dc in direct_copy_list:\n",
    "            qa_dir[dc] = qa_pairs[dc]\n",
    "        # overwrite the last two\n",
    "        qa_dir['Response String'] = qa_pairs['raw answer'] # full, un filtered answer\n",
    "        qa_dir['Response'] = response_claude\n",
    "        qa_out.append(qa_dir.copy())\n",
    "    return qa_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de214bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 2\n",
      "Prompt: I am going to show you an image. Now, how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "  Real A: 50\n",
      "Claude A: {'nbars': 40}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.49755257997301794\n",
      "Claude A: {'maximum x': 0.5}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.34264837991488106\n",
      "Claude A: {'mean x': 0.34}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the median data values in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.3895267656798662\n",
      "Claude A: {'median x': 0.36}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the minimum data values in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.15863689997095148\n",
      "Claude A: {'minimum x': 0.15}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "  Real A: 3\n",
      "Claude A: {'ngaussians': 2}\n",
      "\n",
      "\n",
      "**** Cleaned QA ****\n",
      "Q: I am going to show you an image. Now, how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "ChatGPT A: {'nbars': 40}\n",
      "Real A:    50\n",
      "\n",
      "Q: I am going to show you an image. Now, what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "ChatGPT A: {'maximum x': 0.5}\n",
      "Real A:    0.49755257997301794\n",
      "\n",
      "Q: I am going to show you an image. Now, what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "ChatGPT A: {'mean x': 0.34}\n",
      "Real A:    0.34264837991488106\n",
      "\n",
      "Q: I am going to show you an image. Now, what are the median data values in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median\" value should be a float, calculated from the data values used to create the plot.\n",
      "ChatGPT A: {'median x': 0.36}\n",
      "Real A:    0.3895267656798662\n",
      "\n",
      "Q: I am going to show you an image. Now, what are the minimum data values in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum\" value should be a float, calculated from the data values used to create the plot.\n",
      "ChatGPT A: {'minimum x': 0.15}\n",
      "Real A:    0.15863689997095148\n",
      "\n",
      "Q: I am going to show you an image. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "ChatGPT A: {'ngaussians': 2}\n",
      "Real A:    3\n",
      "\n",
      "Just saved: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/gemini_api/nclust_3_trial9.pickle\n",
      "on 1 of 2\n",
      "have file already: /Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/gemini_api/nclust_5_trial3.pickle\n"
     ]
    }
   ],
   "source": [
    "iMax = 2\n",
    "verbose = False\n",
    "test_run = False # run w/o actually pinging openai\n",
    "restart = False\n",
    "# set system_prompt to None to default to what is in question list\n",
    "system_prompt = \"\"\"You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.\"\"\"\n",
    "#system_prompt = \"\"\"You must respond with only valid JSON. Start your response immediately with { and end with }. Do not write any text before or after the JSON.\"\"\"\n",
    "# temperature=0.1\n",
    "\n",
    "\n",
    "\n",
    "for ijson,json_path in enumerate(jsons_to_parse):\n",
    "    if ijson >= iMax:\n",
    "        continue\n",
    "\n",
    "    print('on', ijson, 'of', iMax)\n",
    "\n",
    "    # get image and base json\n",
    "    img_path = imgs_dir + json_path.split('/')[-1].removesuffix('.json') + '.' + img_format\n",
    "    _, img_format_media, base_json, err = get_img_json_pair(img_path, json_path, \n",
    "                                                            dir_api, restart=restart,\n",
    "                                                      tmp_dir=tmp_dir, load_image=False)\n",
    "    if err:\n",
    "        continue\n",
    "    if verbose: print('Got image!')\n",
    "\n",
    "    ###### create QA ########\n",
    "    qa = []\n",
    "    \n",
    "    for k,v in base_json['VQA']['Level 1']['Figure-level questions'].items():\n",
    "        out = {'Q':v['Q'], 'A':v['A'], 'Level':'Level 1', 'type':'Figure-level questions', 'Response':\"\"}\n",
    "        qa.append(out)\n",
    "    \n",
    "    # what kinds?\n",
    "    types = ['(words + list)', '(words)']\n",
    "    \n",
    "    # get uniques\n",
    "    level_parse = 'Level 1'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 2'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "    \n",
    "    level_parse = 'Level 3'\n",
    "    plot_level = 'Plot-level questions'\n",
    "    qa = parse_qa(level_parse, plot_level, qa, base_json['VQA'], types)\n",
    "\n",
    "    responses = []; prompts = []; system_prompts = []\n",
    "    for question_list in qa:\n",
    "        response, prompt, system_prompt_out = send_to_gemini(question_list, img_path, model_gemini,\n",
    "                    test_run = test_run, \n",
    "                    verbose=verbose,\n",
    "                    system_prompt = system_prompt)\n",
    "        responses.append(response)\n",
    "        question_list['prompt'] = prompt\n",
    "        question_list['system prompt'] = system_prompt_out\n",
    "\n",
    "\n",
    "    # parse for errors\n",
    "    qa = parse_for_errors_claude(qa, llm='claude')\n",
    "    print('')\n",
    "    print('**** Cleaned QA ****')\n",
    "    qa = parse_for_errors(qa) # might need to do this again\n",
    "\n",
    "    # dump to file\n",
    "    if not test_run:\n",
    "        with open(dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle', 'wb') as ff:\n",
    "            pickle.dump([qa, model], ff)\n",
    "        print('Just saved:', dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n",
    "    else:\n",
    "        print('Would store at:', dir_api + json_path.split('/')[-1].removesuffix('.json')+ '.pickle')\n",
    "    #import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9815e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d2fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2b90896",
   "metadata": {},
   "source": [
    "## Look at data\n",
    "\n",
    "Check out one, if you wanna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8540406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/gemini_api/nclust_5_trial3.pickle',\n",
       " '/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/gemini_api/nclust_3_trial9.pickle']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickles = glob(dir_api + '*.pickle')\n",
    "#pickles = glob('/Users/jnaiman/Downloads/tmp/JCDL2025/example_hists/claude_api/*pickle')\n",
    "pickles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc36f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifile = 1\n",
    "with open(pickles[ifile], 'rb') as f:\n",
    "    qa_in = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc0a5ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q': 'You are a helpful assistant that can analyze images.  How many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.',\n",
       " 'A': 50,\n",
       " 'Level': 'Level 1',\n",
       " 'type': 'Plot-level questions',\n",
       " 'persona': 'You are a helpful assistant that can analyze images.',\n",
       " 'context': '',\n",
       " 'question': 'How many bars are there in the specified figure panel?',\n",
       " 'format': 'Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.',\n",
       " 'plot number': 'plot0',\n",
       " 'usage': {'input_tokens': 310,\n",
       "  'output_tokens': 13,\n",
       "  'total_tokens': 323,\n",
       "  'cached_content_tokens': 0},\n",
       " 'prompt': 'I am going to show you an image. Now, how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.',\n",
       " 'system prompt': 'You are a helpful assistant that responds only in valid JSON format. Do not include any explanations, reasoning, or text outside of the JSON response.',\n",
       " 'Response': {'nbars': 40},\n",
       " 'Response String': '```json\\n{\"nbars\": 40}\\n```'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_in[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5630fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qa_in = parse_for_errors_claude(qa_in, llm='gemini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63377f",
   "metadata": {},
   "source": [
    "Claude outputs reasoning, so we have to do a bit of cleaning from the responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e69ab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jnaiman/LLM_VQA_JCDL2025/example_hists/LLM_outputs/gemini_api/nclust_3_trial9.pickle\n",
      "*********\n",
      "Prompt: I am going to show you an image. Now, how many bars are there in the specified figure panel? Please format the output as a json as {\"nbars\":\"\"} for this figure panel, where the \"nbars\" value should be an integer.\n",
      "  Real A: 50\n",
      "Claude A: {'nbars': 40}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the maximum data values in this figure panel?  Please format the output as a json as {\"maximum x\":\"\"} for this figure panel, where the \"maximum\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.49755257997301794\n",
      "Claude A: {'maximum x': 0.5}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the mean data values in this figure panel?  Please format the output as a json as {\"mean x\":\"\"} for this figure panel, where the \"mean\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.34264837991488106\n",
      "Claude A: {'mean x': 0.34}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the median data values in this figure panel?  Please format the output as a json as {\"median x\":\"\"} for this figure panel, where the \"median\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.3895267656798662\n",
      "Claude A: {'median x': 0.36}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, what are the minimum data values in this figure panel?  Please format the output as a json as {\"minimum x\":\"\"} for this figure panel, where the \"minimum\" value should be a float, calculated from the data values used to create the plot.\n",
      "  Real A: 0.15863689997095148\n",
      "Claude A: {'minimum x': 0.15}\n",
      "\n",
      "Prompt: I am going to show you an image. Now, how many gaussians were used to generate the data for the plot in the figure panel? Please format the output as a json as {\"ngaussians\":\"\"} for this figure panel, where the \"ngaussians\" value should be an integer.\n",
      "  Real A: 3\n",
      "Claude A: {'ngaussians': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pickles[ifile])\n",
    "print('*********')\n",
    "for qa_pairs in qa_in:\n",
    "    print('Prompt:', qa_pairs['prompt'])\n",
    "    print('  Real A:', qa_pairs['A'])\n",
    "    print('Claude A:', qa_pairs['Response'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57affca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JCDL2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
